[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PHCM9795: Foundations of Biostatistics",
    "section": "",
    "text": "Course introduction\nWelcome to PHCM9795 Foundations of Biostatistics.\nThis introductory course in biostatistics aims to provide students with core biostatistical skills to analyse and present quantitative data from different study types. These are essential skills required in your degree and throughout your career.\nWe hope you enjoy the course and will value your feedback and comment throughout the course."
  },
  {
    "objectID": "index.html#course-information",
    "href": "index.html#course-information",
    "title": "PHCM9795: Foundations of Biostatistics",
    "section": "Course information",
    "text": "Course information\nBiostatistics is a foundational discipline needed for the analysis and interpretation of quantitative information and its application to population health policy and practice.\nThis course is central to becoming a population health practitioner as the concepts and techniques developed in the course are fundamental to your studies and practice in population health. In this course you will develop an understanding of, and skills in, the core concepts of biostatistics that are necessary for analysis and interpretation of population health data and health literature.\nIn designing this course, we provide a learning sequence that will allow you to obtain the required graduate capabilities identified for your program. This course is taught with an emphasis on formulating a hypothesis and quantifying the evidence in relation to a specific research question. You will have the opportunity to analyse data from different study types commonly seen in population health research.\nThe course will allow those of you who have covered some of this material in your undergraduate and other professional education to consolidate your knowledge and skills. Students exposed to biostatistics for the first time may find the course challenging at times. Based on student feedback, the key to success in this course is to devote time to it every week. We recommend that you spend an average of 10-15 hours per week on the course, including the time spent reading the course notes and readings, listening to lectures, and working through learning activities and completing your assessments. Please use the resources provided to assist you, including online support."
  },
  {
    "objectID": "index.html#units-of-credit",
    "href": "index.html#units-of-credit",
    "title": "PHCM9795: Foundations of Biostatistics",
    "section": "Units of credit",
    "text": "Units of credit\nThis course is a core course of the Master of Public Health, Master of Global Health and Master of Infectious Diseases Intelligence programs and associated dual degrees, comprising 6 units of credit towards the total required for completion of the study program. A value of 6 UOC requires a minimum of 150 hours work for the average student across the term."
  },
  {
    "objectID": "index.html#course-aim",
    "href": "index.html#course-aim",
    "title": "PHCM9795: Foundations of Biostatistics",
    "section": "Course aim",
    "text": "Course aim\nThis course aims to provide students with the core biostatistical skills to apply appropriate statistical techniques to analyse and present population health data."
  },
  {
    "objectID": "index.html#learning-outcomes",
    "href": "index.html#learning-outcomes",
    "title": "PHCM9795: Foundations of Biostatistics",
    "section": "Learning outcomes",
    "text": "Learning outcomes\nOn successful completion of this course, you will be able to:\n\nSummarise and visualise data using statistical software.\nDemonstrate an understanding of statistical inference by interpreting p-values and confidence intervals.\nApply appropriate statistical tests for different types of variables given a research question, and interpret computer output of these tests appropriately.\nDetermine the appropriate sample size when planning a research study.\nPresent and interpret statistical findings appropriate for a population health audience."
  },
  {
    "objectID": "01-intro.html",
    "href": "01-intro.html",
    "title": "1  Introduction to statistics and presenting data",
    "section": "",
    "text": "An introduction to Stata"
  },
  {
    "objectID": "01-intro.html#learning-objectives",
    "href": "01-intro.html#learning-objectives",
    "title": "1  Introduction to statistics and presenting data",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of this module, you will be able to:\n\nDefine the term statistics;\nDescribe and identify the underpinning concepts of descriptive and inferential statistics;\nDistinguish between different types of variables (i.e. quantitative – discrete and continuous; and qualitative – ordinal and nominal);\nConstruct appropriate frequency tables from raw data;\nCompute summary statistics to describe the centre and spread of data;\nDescribe the (centre and spread of the) data using appropriate graphs (histogram and box plot);\nPresent and interpret graphical summaries of variables using a variety of graphs (bar charts, line-graphs, histograms, boxplots, pie charts and others)."
  },
  {
    "objectID": "01-intro.html#readings",
    "href": "01-intro.html#readings",
    "title": "1  Introduction to statistics and presenting data",
    "section": "Readings",
    "text": "Readings\nKirkwood and Sterne (2001); Chapters 2 and 3. [UNSW Library Link]\nBland (2015); Chapter 4. [UNSW Library Link]\nAcock (2010); Chapter 5.\nGraphics and statistics for cardiology: designing effective tables for presentation and publication, Boers (2018) [UNSW Library Link]\nGuidelines for Reporting of Figures and Tables for Clinical Research in Urology, Vickers et al. (2020) [UNSW Library Link]"
  },
  {
    "objectID": "01-intro.html#an-introduction-to-statistics",
    "href": "01-intro.html#an-introduction-to-statistics",
    "title": "1  Introduction to statistics and presenting data",
    "section": "1.1 An introduction to statistics",
    "text": "1.1 An introduction to statistics\nThe dictionary of statistics (Upton and Cook, 2008) defines statistics simply as: “The science of collecting, displaying, and analysing data.”\nStatistics is a branch of mathematics, together with theoretical/pure mathematics and applied mathematics. Within the field of statistics, there are two main divisions: mathematical statistics and applied statistics. Mathematical statistics deals with development of new methods of statistical inference and requires detailed knowledge of abstract mathematics for its implementation. Applied statistics applies the methods of mathematical statistics to specific subject areas, such as business, psychology, medicine and sociology.\nBiostatistics can be considered as the “application of statistical techniques to the medical and health fields”. However, biostatistics sometimes overlaps with mathematical statistics. For instance, given a certain biostatistical problem, if the standard methods do not apply then existing methods must be modified to develop a new method.\n\n1.1.1 Scope of Biostatistics\nResearch is essential in the practice of health care. Biostatistical knowledge helps health professionals in deciding whether to prescribe a new drug for the treatment of a disease or to advise a patient to give up drinking alcohol. To practice evidence-based healthcare, health professionals must keep abreast of the latest research, which requires understanding how the studies were designed, how data were collected and analysed, and how the results were interpreted. In clinical medicine, biostatistical methods are used to determine the accuracy of a measurement, the efficacy of a drug in treating a disease, in comparing different measurement techniques, assessing diagnostic tests, determining normal values, estimating prognosis and monitoring patients. Public health professionals are concerned about the administration of medical services or ensuring that an intervention program reduces exposure to certain risk factors for disease such as life-style factors (e.g. smoking, obesity) or environmental contaminants. Knowledge of biostatistics helps determine them make decisions by understanding, from research findings, whether the prevalence of a disease is increasing or whether there is a causal association between an environmental factor and a disease.\nThe value of biostatistics is to transform (sometimes vast amounts of) data into meaningful information, that can be used to solve problems, and then be translated into practice (i.e. to inform public health policy and decision making). When undertaking research having a biostatistician as part of a multidisciplinary team from the outset, together with scientists, clinicians, epidemiologists, healthcare specialists is vital, to ensure the validity of the research being undertaken and that information is interpreted appropriately."
  },
  {
    "objectID": "01-intro.html#descriptive-and-inferential-statistics",
    "href": "01-intro.html#descriptive-and-inferential-statistics",
    "title": "1  Introduction to statistics and presenting data",
    "section": "1.2 Descriptive and inferential statistics",
    "text": "1.2 Descriptive and inferential statistics\nTo understand the concepts of statistics, it is important to realise there are two ways of using data: one is via descriptive statistics and the other is via inferential statistics.\n\n1.2.1 Descriptive statistics\nDescriptive statistics provide a ‘picture’ of the characteristics of a population. Examples of descriptive statistics based on the population are given below.\n\n1.2.1.1 Births\nThese examples on descriptive statistics consider all the births in Australia in 2019 (Australian Institute of Health and Welfare (2021)). The Australian Institute of Health and Welfare produce comprehensive reports annually on the characteristics of Australia’s mothers and babies of the most recent year of data from the National Perinatal Data Collection.\nOne headline from the report is “Nearly two thirds of mothers were aged between 25 and 34 years (185,958 women in 2019)”, which is accompanied by a figure illustrating the age distribution of mothers in Australia giving birth in 2019. This example shows descriptive statistics that are presented as the actual number of women giving birth in 2019, together with a comparison of age distributions across Australian states.\nFurther descriptive statistics provide summary information, about the average (mean) age of women giving birth in 2019 (30.8 years) and the proportion of mothers who were Indigenous (4.8%).\n\n\n1.2.1.2 Deaths\nIn another example, consider characteristics of all the deaths in Australia in 2020 (Australian Bureau of Statistics (2021)).\n\n“During the pandemic many countries saw a change in mortality patterns, including COVID-19 becoming a leading cause of death.”\n\nThe report presents the leading causes of death in 2020, comparing the age-standardised rates between 2019 and 2020:\n\n“The top five leading causes of death remained the same as in 2019 (Ischaemic heart disease, Dementia including Alzheimer’s disease, Cerebrovascular diseases, Lung cancer and Chronic lower respiratory diseases).\nThe age-standardised death rate decreased for all top five leading causes of death from 2019.\nDeaths due to chronic lower respiratory diseases (including emphysema) had the highest proportional rate decrease from 2019 at 17.8%.\nThe reduction in acute respiratory conditions such as pneumonia contributed to a decrease in the top five leading causes of death.\nAll top five leading causes of death are non-communicable diseases (they are not passed from person to person).”\n\nThe information was also presented as a visualisation / infographic, demonstrating a simplistic, yet valuable way of presenting data and enabling rates of death for 2019 and 2020.\n\n\n\n\n\nFigure 1.1: Age-standardised death rates for the top five leading causes, 2019-2020\n\n\n\n\n\n\n\n1.2.2 Inferential statistics\nInferential statistics use data collected from a sample of the population, to make conclusions (inferences) about the whole population (that the sample was drawn from).\nThe following example is about a sample of prisoners, from the National Prisoner Health Data Collection (NPHDC). The NPHDC is the main source of national data about the health of prisoners in Australia. It gathers information over a 2-week period from prison entrants, dischargees, prisoners visiting the prison health clinic, and prisoners taking prescribed medication.\nWe have information about the population of prisoners, given as the number of prisoners in Australia’s prisons from the ABS website:\n\nAt 30 June 2015: There were 36,134 prisoners in Australian prisons, an increase of 7% (2,345 prisoners) from 30 June 2014.\n\nCharacteristics (sex, age group and Indigenous status) of the sample of prisoners from the NPHDC are given in the following table. We can use this information to make inferences about the whole population of prisoners that the sample was drawn from.\n\n\n\n\n\nFigure 1.2: Characteristics of the sample of prisoners from the NPHDC"
  },
  {
    "objectID": "01-intro.html#variables",
    "href": "01-intro.html#variables",
    "title": "1  Introduction to statistics and presenting data",
    "section": "1.3 Variables",
    "text": "1.3 Variables\nA variable is simply a characteristic that is being measured or observed. For example, height, weight, eye colour, income, country of birth are all types of variables.\nWhen we are examining associations between variables, we may also use the terms: outcome variable (sometimes called a dependent variable) and explanatory variable (sometimes called an independent variable).\nFor example, some rural areas of Bangladesh have a very high concentration of arsenic in the drinking water. Children who consume arsenic-contaminated water become malnourished. In this example, being malnourished is the outcome variable which is being caused, or influenced, by the exposure variable: arsenic-contaminated water. Thus, the outcome variable is the variable of interest which may change in response to some exposure.\n\n1.3.1 Types of data\nData are groups of information that represent the qualitative or quantitative attributes of variables or a group of variables. For example, the ages of students attending a university gym in a particular hour were recorded. The thirty ages are given below:\n\n\n\n\nTable 1.1:  Age of 30 gym attendees \n\n181720212319\n\n191818202123\n\n202319211920\n\n202219222021\n\n182324182021\n\n\n\n\n\nThe variable here is age and there are 30 observations recorded.\nQuantitative data are numerical data that can be measured or counted such as age, weight, height, etc. These data can be discrete or continuous. Biostatistics mostly deals with quantitative variables or numerical data.\nA discrete variable can have only one of a distinct set of values. For a discrete variable, observations are based on a count where both ordering and magnitude are important, such that numbers represent actual measurable quantities rather than mere labels.\nFor example, the number of cancer cases in a specified area emerging over a certain period, the number of motorbike accidents in Sydney, the number of times a woman has given birth, the number of beds in a hospital. It is noteworthy that natural ordering exists among the data points, that is, a hospital with 100 beds has more beds than a hospital with 75 beds. Moreover, a difference between 40 and 50 beds is the same as the difference between 80 and 90 beds. A discrete variable can take only non-negative integer values: a woman cannot have 5.7 births. However, we can calculate summaries of discrete variables that are not necessarily discrete. For instance, if one woman has given birth four times and another woman five times, then on average, these two women have 4.5 births.\nContinuous data can take any values within a defined range.\nFor example, age, height, weight or blood pressure, are continuous variables because we can make any divisions we want on them, and they can be measured as small as the instrument allows. As an illustration, if two people have the same blood pressure measured to the nearest millimetre of mercury, we may get a difference between them if the blood pressure is measured to the nearest tenth of millimetre. If they are still the same (to the nearest tenth of a millimetre), we can measure them with even finer gradations until we can see a difference.\nQualitative data have values that describe a ‘quality’ or ‘characteristic’. Categorical data are qualitative data and do not have measurable numeric values. These data can be nominal or ordinal.\nA nominal variable consists of unordered categories. For example, gender, race, ethnic group, religion, eye colour etc. Both the order and magnitude of a nominal variable are unimportant. If a nominal variable takes on one of two distinct categories, such as black or white then it is called dichotomous or binary variable. Other examples would be male or female; smoker or non-smoker; exposed to arsenic or not exposed. A number is often used to represent (label) each of the categories; for example, males could be assigned the value 1 and females 0; in the case of exposed and unexposed, exposed could be assigned 1 and unexposed 0. A nominal variable can also have more than two categories, such as blood group, with labels and categories as follows (1=Group A, 2=Group B, 3=Group AB, 4=Group O). Numbers are used for the sake of convenience of analysis when using a computer package.\nOrdinal data consist of ordered categories where differences between categories are important, such as socioeconomic status (low, medium, high) or student evaluation rating could be classified according to their level of satisfaction, where 1 represents excellent, 2 is satisfactory and 3 is unsatisfactory. Here natural order exists among the categories, where a smaller number represents higher satisfaction."
  },
  {
    "objectID": "01-intro.html#presenting-data",
    "href": "01-intro.html#presenting-data",
    "title": "1  Introduction to statistics and presenting data",
    "section": "1.4 Presenting data",
    "text": "1.4 Presenting data\nWe will now look at ways to present frequency information numerically in tables and graphs.\n\n1.4.1 Frequency tables\n\n1.4.1.1 Worked example\nConsider the ages of 30 students visiting a university gym in a particular hour presented in Table 1.1. This information is difficult to interpret in its raw form, but becomes more clear if the ages are grouped in a frequency table as shown in Table 1.2.\n\n\n\n\nTable 1.2:  Frequency of ages of students visiting a gym \n\nAgeFrequency\n\n171\n\n185\n\n195\n\n207\n\n215\n\n222\n\n234\n\n241\n\nTotal30\n\n\n\n\n\nThe frequency is a count of the number of individuals of each age in the corresponding row. Three more columns can be added to the frequency table to give further insight: relative frequency, cumulative frequency and cumulative relative frequency (Table 1.3).\n\n\n\n\nTable 1.3:  Frequency of ages of students visiting a gym \n\nAgeFrequencyRelative frequency (%)Cumulative frequencyCumulative relative frequency (%)\n\n171313\n\n18517620\n\n195171137\n\n207231860\n\n215172377\n\n22272583\n\n234132997\n\n241330100\n\nTotal30100\n\n\n\n\n\nThe relative frequency is the frequency expressed as a proportion or percentage of the total frequency. For example, 5 out of 30 students are aged 21, so the relative frequency is (5/30) \\(\\times\\) 100 = 16.7%.\nThe cumulative frequency here shows the total number of students less than or equal to a certain age, while the cumulative relative frequency is the percentage (of the total) who are less than a certain age. For example, the cumulative frequency of students at the gym aged 19 years or less is 1 + 5 + 5 = 11, and the cumulative relative frequency is (11/30) \\(\\times\\) 100 = 36.7%.\nThe information presented in Table 1.3 is called the frequency distribution of the variable age. Frequency distributions can also be presented for qualitative (categorical) data.\nFor example, if we know that there are 12 males and 18 females in our data, this can be presented as in Table 1.4. We should not interpret the cumulative frequency for nominal data (e.g. gender, eye colour or cancer types) as these data cannot be ranked. However, we can calculate the cumulative frequency for ordinal data (e.g. student satisfaction level, cancer stage).\n\n\n\n\nTable 1.4:  Frequency of sex of students visiting a gym \n\nSexFrequencyRelative frequency (%)\n\nMale1240\n\nFemale1860\n\nTotal30100\n\n\n\n\n\n\n\n\n1.4.2 Tables with more than one variable\nSo far, we have discussed one-way frequency tables, that is, tables that summarise one variable. We can summarise more than one variable in a table – called a cross tabulation, or a two-way (summarising two variables) table or multi-way (summarising more than two variables) table. However, tables become complex when more than two variables are incorporated (you may need to present the information as two tables or incorporate additional rows and columns).\nIn our example above, if we have two categorical variables (e.g. sex with two categories male and female and BMI status with three categories Normal, Overweight and Obese) measured on each subject (student), we can classify the two variables simultaneously using two-way tables of frequency as shown in Table 1.5.\n\n\n\n\nTable 1.5:  Frequency of students visiting a gym by sex and BMI status* \n\nSexNot overweightOverweightObeseTotal\n\nMale19212\n\nFemale116017\n\nTotal1215329\n\n*BMI was missing for 1 student\n\n\n\n\n\n\n\n1.4.3 Tables containing more than two variables\nIn Figure 1.2, characteristics of the sample of prisoners from the NPHDC were presented. This table contains information about sex, age group and Indigenous status from different groups of prisoners; prison entrants, discharges, and prisoners in custody. This type of condensed information is often found in reports and journal articles giving demographic information, by different groups considered in the study.\nWe might also consider a table containing further pieces of information. The table presented in Figure 1.3 (from the health of Australia’s prisoners 2015 report) compares prison entrants and the general community by three variables: age group, Indigenous status, and highest level of completed education.\nCan you see any issues with the presentation of this table?\n\n\n\n\n\nFigure 1.3: Highest level of completed education in prison entrants and the general community\n\n\n\n\nSource: Australian Institute of Health and Welfare 2015. The health of Australia’s prisoners 2015. Cat. no. PHE 207. Canberra: AIHW.\nSome issues in this table:\n\nThe title of the table does not contain full information about the variables in the table;\nIt is unclear how the percentages were calculated (which groupings added to 100%);\nThe ages are not labelled as such, thus without reading the text in report it is unclear that these are age groupings.\n\n\n\n1.4.4 Table presentation guidelines (Woodward, 2013)\n\nEach table (and figure) should be self-explanatory, i.e. the reader should be able to understand it without reference to the text in the body of the report.\n\nThis can be achieved by using complete, meaningful labels for the rows and columns and giving a complete, meaningful title.\nFootnotes can be used to enhance the explanation.\n\nUnits of the variables (and if needed, method of calculation or derivation) should be given and missing records should be noted (e.g. in a footnote).\nA table should be visually uncluttered.\n\nAvoid use of vertical lines.\nHorizontal lines should not be used in every single row, but they can be used to group parts of the table.\nSensible use of white space also helps enormously; use equal spacing except where large spaces are left to separate distinct parts of the table.\nDifferent typefaces (or fonts) may be used to provide discrimination, e.g. use of bold type and/or italics.\n\nThe rows and columns of each table should be arranged in a natural order to help interpretation. For instance, when rows are ordered by the size of the numbers they contain for a nominal variable, it is immediately obvious where relatively big and small contributions come from.\nTables should have a consistent appearance throughout the report so that the paper is easy to follow (and also for an aesthetic appearance). Conventions for labelling and ordering should be the same (for both tables as well as figures) for ease of comparison of different tables (and figures).\nConsider if there is a particular table orientation that makes a table easier to read.\n\nGiven the different possible formats of tables and their complexity, some further guidelines are given in the following excellent references:\n\nGraphics and statistics for cardiology: designing effective tables for presentation and publication, Boers (2018)\nGuidelines for Reporting of Figures and Tables for Clinical Research in Urology, Vickers et al. (2020)"
  },
  {
    "objectID": "01-intro.html#graphical-presentation",
    "href": "01-intro.html#graphical-presentation",
    "title": "1  Introduction to statistics and presenting data",
    "section": "1.5 Graphical presentation",
    "text": "1.5 Graphical presentation\n\n1.5.1 Bar graphs\nUsing the PBC data from the Introduction to Stata or Introduction to R exercise, we can present the distribution of Stage of Disease graphically using a bar graph (Figure 1.4). Bar graphs, which are suitable for plotting discrete or categorical variables, are defined by the fact that the bars do not touch.\n\n\n\n\n\nFigure 1.4: Bar graph of stage of disease from PBC study\n\n\n\n\nInformation from more than one variable can be presented as clustered or multiple bar chart (bars side-by-side) (Figure 1.5). This type of graph is useful when examining changes in the categories separately, but also comparing the grouping variable between the main bar variable. Here we can see that Stage 3 and Stage 4 disease is the most common for both males and females, but there are many more females within each stage of disease.\n\n\n\n\n\nFigure 1.5: Bar graph of stage of disease by sex from PBC study\n\n\n\n\nAn alternative bar graph is a stacked or composite bar graph, which retains the overall height for each category, but differentiates the bars by another variable (Figure 1.6).\n\n\n\n\n\nFigure 1.6: Stacked bar graph of stage of disease by sex from PBC study\n\n\n\n\nFinally, a stacked relative bar chart (Figure 1.7) displays the proportion of grouping variable for each bar, where each overall bar represents 100%. These graphs allow the reader to compare the proportions between categories. We can easily see from Figure 1.7 that the distribution of sex is similar across each stage of disease.\n\n\n\n\n\nFigure 1.7: Relative frequency of sex within stage of disease from PBC study\n\n\n\n\n\n\n1.5.2 Line graphs\nA line graph is effective to illustrate trends over time (e.g. change over several years). Let’s look at an example from cancer epidemiology.\nCancer incidence is the number of new cases of cancer diagnosed in a population in a given time period. A useful comparison with the incidence rate is the mortality rate, revealing information about the deaths from cancer in the same period. Figure 1.8 shows the prostate cancer trend in the NSW male population in the period 1972-2014, specifically the age-standardised incidence and mortality rate per 100,000.\n\n\n\n\n\nFigure 1.8: Prostate cancer age-standardised incidence and mortality rates (per 100,000), NSW, 1972-2014\n\n\n\n\nSource: The Cancer Institute NSW (2018) Cancer statistics NSW. https://www.cancer.nsw.gov.au/cancer-statistics-nsw (Accessed: 24 Jan 2019).\nThe age standardised incidence rate for prostate cancer increased steadily in the period 1972 – 1991, from 55.2 cases per 100,00 to 109.3 cases per 100,000. There were two notable peaks in incidence in the period 1972-2014. In particular, there was an increase between 1992-1994, and also between 2002-2009. Since 2009 (to 2014) the rates decreased from 198.9 per 100,000 to 148.2 per 100,000. Whilst the incidence rate for prostate cancer has fluctuated over the period, the age standardised mortality rate remained relatively stable (around 35 deaths per 100,000). Since 2009 the mortality rate appears to be decreasing and was at its lowest in 2014 at 22.1 per 100,000.\n[The increase in prostate cancer incidence in the early 1990’s occurred at a time when blood testing of men for Prostate Specific Antigen (PSA) became more widespread. The more recent peak in incidence in the early 2000’s maybe explained by PSA being increasingly used as a screening test for men who did not have symptoms of prostate cancer.]\n\n\n1.5.3 Pie charts\nAn example of graphical presentation that we would recommend avoiding, is a pie chart. These are often used to present the proportion of each category that contributed to the total. However, their use is limited and sometimes misleading, and the same information can be presented as a stacked bar chart of proportions. Here are some reasons why not to use pie charts:\n\nNot ideal when there are many categories to compare\nThe use of percentages is not appropriate when the sample size is small\nCan be misleading by using different size pies, different rotations and different colours to draw attention to specific groups\n3D and exploding bar charts further distort the effect of perspective and may confuse the reader\n\n\n\n1.5.4 Graphical presentation guidelines\nConsider the following guidelines for the appropriate presentation of graphs in scientific journals and reports (Woodward, 2013).\n\nFigures should be self-explanatory and have consistent appearance through the report.\nA title should give complete information. Note that figure titles are usually placed below the figure, whereas for tables titles are given above the table.\nAxes should be labelled appropriately\nUnits of the variables should be given in the labelling of the axes. Use footnotes to indicate any calculation or derivation of variables and to indicate missing values\nIf the Y-axis has a natural origin, it should be included, or emphasised if it is not included.\nIf graphs are being compared, the Y-axis should be the same across the graphs to enable fair comparison\nColumns of bar charts should be separated by a space\nThree dimensional graphs should be avoided unless the third dimension adds additional information"
  },
  {
    "objectID": "01-intro.html#summary-statistics-and-variation-in-data",
    "href": "01-intro.html#summary-statistics-and-variation-in-data",
    "title": "1  Introduction to statistics and presenting data",
    "section": "1.6 Summary statistics and variation in data",
    "text": "1.6 Summary statistics and variation in data\nWe often collect measurements that are continuous in nature, that is measurements such as height, weight, time, blood pressure etc which can be measured accurately to one or more decimal places. A useful way of describing the continuous data is via summary statistics. These include measures to describe the distribution of data points via the central tendency (e.g. mean, median) and spread (e.g. standard deviation and inter quartile range). We also examine the data visually by graphing it using histograms and box plots.\n\n1.6.1 Mathematical and statistical notation\nWhen computing summary statistics or using more formal statistical methods, mathematical and statistical notation is often used. Below are some of the common statistical terms and interpretation that will be used in the course and which are seen in many text books.\n\n\n\nNotation\nInterpretation\n\n\n\n\n\\(x\\)\nAn observation in your sample\n\n\n\\(\\sum x\\)\nSum of all the observations\n\n\n\\(N\\)\nTotal population size\n\n\n\\(n\\)\nSample size\n\n\n\\(\\mu\\) (mu)\nPopulation mean\n\n\n\\(\\sigma^2\\)\nPopulation variance\n\n\n\\(\\sigma\\)\nPopulation standard deviation\n\n\n\\(\\bar{x}\\)\nSample mean\n\n\n\\(s^2\\)\nSample variance\n\n\n\\(s\\)\nSample standard deviation\n\n\n\n\n\n1.6.2 Measures of central tendency\n\n1.6.2.1 Worked example\nIn our random sample of 30 students attending a university gym on a given day, their weight in kilograms was measured (see below). Weight is a continuous measurement (similar to height, blood pressure etc) that in theory can be measured to infinitely small units, though in practice they can be measured accurately to one or two decimal places.\nWe will use these data to look at measures of central tendency and spread of the data and other summary statistics.\n60.0\n62.5 62.5 62.5\n65.0 65.0 65.0\n67.5 67.5 67.5 67.5 67.5\n70.0 70.0 70.0 70.0 70.0 70.0 72.5 72.5 72.5 72.5\n75.0 75.0 75.0 75.0 75.0\n77.5 77.5\n80.0\n\n\n1.6.2.2 Mean\nThe most commonly used measure of the central tendency of the data is the mean value. The mean of a set of values is often referred to as the average of all the values. The mean (\\(\\bar{x}\\)) of a sample dataset is calculated using the following formula:\n\\[\\bar{x} = \\frac{\\sum x}{n}\\]\nFrom the weights example: \\(\\bar{x}\\) = 2100/30 = 70.0. Thus, the mean weight of this sample is 70.0 kg\n\n\n1.6.2.3 Median and mode\nOther measures of central tendency include the median and mode. The median is the true centre of the data, the value at which half of the measurements lie above it and half of the measurements lie below it.\nTo estimate the median, the data are ordered from the lowest to highest values, and the middle value is used. If the middle value is between two data points (if there are an even number of observations), the median is an average of the two values. Using the weight example, the median would be 70.0 kg.\nFor a set of eight exam results ranked in order:\n48 51 55 59 63 64 69 75\nThe median is the average of the two middle observations: 59 and 63. So the median is (59+63)/2 = 61\nThe mode is the most frequent value in the distribution, in the weight example this would be 70.0 kg as this value features most frequently. The mode is not used frequently.\n\n\n\n1.6.3 Describing the spread of the data\nIn addition to measuring the centre of the data, we also need a robust estimate of the spread of the data points.\n\n1.6.3.1 Range\nThe absolute measure of the spread of the data is the range, that is the difference between the highest and lowest values in the dataset.\nRange = highest data value – lowest data value\nUsing the weights example, Range = 80.0 - 60.0 = 20.0 kg\nNote that while the range is 20.0 kg, the range is often reported as the actual lowest and highest values e.g. Range 60 to 80 kg.\nThe range is not always ideal as it only describes the extreme values, without considering how the bulk of the data is distributed between them.\n\n\n1.6.3.2 Variance and standard deviation\nMore useful statistics to describe the spread of the data around a mean value are the variance and standard deviation. These measures of variability depend on the difference between individual observations and the mean value (deviations). If all values are equal to the mean there would be no variability at all, all deviations would be zero; conversely large deviations indicate greater variability.\nOne way of combining deviations in a single measure is to first square the deviations and then average the squares. Squaring is done because we are equally interested in negative deviations and positive deviations; if we averaged without squaring, negative and positive deviations would ‘cancel out’. This measure is called the variance of the set of observations. It is ‘the average squared deviation from the mean’. Because the variance is in ‘square’ units and not in the units of the measurement, a second measure is derived by taking the square root of the variance. This is the standard deviation (SD), and is the most commonly used measure of variability in practice, as it is a more intuitive interpretation since it is in the same units as the units of measurement (adapted from: Williams, 2015).\nThe formula for the variance of a sample (\\(s^2\\)) is:\n\\[ s^2 = \\frac{\\sum(x - \\bar{x})^2}{n-1} \\]\nNote that the deviations are first squared before they are summed to remove the negative values; once summed they are divided by the sample size minus 1.\nThe sample standard deviation is the square root of the of the sample variance:\n\\[s = \\sqrt{s^2}\\] For the worked weights example, we would calculate the sample variance:\n\\[\\begin{aligned}\n  s^2 &= \\frac{(60.0 - 70.0)^2 + (62.5 - 70.0)^2 + \\dots + (80.0 - 70.0)^2}{30-1} \\\\\n      &= \\frac{737.5}{29} \\\\\n      &= 25.43 \\text{ kg}^2\n  \\end{aligned}\\]\nwith a sample standard deviation: \\(s = \\sqrt{25.43} = 5.04 \\text{ kg}\\).\nThus, in our sample of 30 students, we have an estimated mean weight of 70.0 kg, with a variance of 25.43 kg2 and a standard deviation of 5.04 kg.\nCharacteristics of the standard deviation - It is affected by every measurement - It is in the same units as the measurements - It can be converted to measures of precision (standard error and 95% confidence intervals) (Module 3)\nInterquartile range The inter-quartile range (IQR) describes the range of measurements in the central 50% of values around the median i.e. the bottom 25% and top 25% of values are discarded and only the values in the 25%-75% range are quoted. The IQR is the preferred measure of spread when the median has been used to describe central tendency.\nIn the weights example the IQR would be 67.5 – 75.0 (i.e. the middle 50% of values)."
  },
  {
    "objectID": "01-intro.html#population-values-mean-variance-and-standard-deviation",
    "href": "01-intro.html#population-values-mean-variance-and-standard-deviation",
    "title": "1  Introduction to statistics and presenting data",
    "section": "1.7 Population values: mean, variance and standard deviation",
    "text": "1.7 Population values: mean, variance and standard deviation\nThe examples above show how the sample mean, range, variance and standard deviation are calculated from the sample of weight measures from 30 people. If we had information on the weight of the total population that the sample was drawn from, we could calculate all the summary statistics described above (for the sample) for the population.\nThe equation for calculating the population mean is the same as that of sample mean, though now we denote the population mean as μ:\n\\[ \\mu = \\frac{\\sum{x}}{N} \\]\nWhere \\(\\sum{x}\\) represents the sum of the values in the population, and \\(N\\) represents the total number of measurements in the population.\nTo calculate the population variance (\\(\\sigma^2\\)) and standard deviation(\\(\\sigma\\)), we use a slightly modified version of the equation for \\(s^2\\):\n\\[ \\sigma^2 = \\frac{\\sum(x - \\mu)^2}{N} \\]\nwith a population standard deviation of: \\(\\sigma = \\sqrt{\\sigma^2}\\).\nIn practice, we rarely have the information for the entire population to be able to calculate the population mean and standard deviation. Theoretically, however, these statistics are important for two main purposes:\n\nthe characteristics of the normal distribution (the most important probability distribution discussed in later modules) are defined by the population mean and standard deviation;\nwhile calculating sample sizes (discussed in later modules) we need information about the population standard deviation, which is usually obtained from the existing literature."
  },
  {
    "objectID": "01-intro.html#using-graphs-to-display-the-centre-and-spread-of-the-data",
    "href": "01-intro.html#using-graphs-to-display-the-centre-and-spread-of-the-data",
    "title": "1  Introduction to statistics and presenting data",
    "section": "1.8 Using graphs to display the centre and spread of the data",
    "text": "1.8 Using graphs to display the centre and spread of the data\nAs well as calculating measures of central tendency and spread to describe the characteristics of the data, a graphical plot is very helpful to better understand the characteristics and distribution of the measurements obtained. Histograms and box plots are excellent ways to graphically display continuous data.\n\n1.8.1 Frequency histograms\nA histogram that plots the frequency of the grouped observations is called a frequency histogram. Some features of a frequency histogram:\n\nThe area under each rectangle is proportional to the frequency\nThe rectangles are drawn without gaps between them (unlike a bar graph)\nThe data are ‘binned’ into discrete intervals (of (usually of equal width)\nThe mid-point of the histogram represents the centre (mean, median) of the data\n\nIf the rectangles are symmetrically distributed about the middle of the histogram, we say that the data are symmetric, and the mean and median will be approximately equal.\nIf the histogram has a longer tail to the right, then the data are said to be positively skewed (or skewed to the right), and the mean will be greater than the median.\nIf the histogram has an extended tail to the left, then the data are negatively skewed (or skewed to the left) and the mean will be smaller than the median.\n\nThe skewness of a distribution is defined by the location of the longer tail, not the location of the peak of the data.\n\nFigure 1.9 presents two histograms from the PBC data from the Introduction to Stata exercise: for age and serum bilirubin. We can see that the distribution for age is roughly symmetric, while the distribution for serum bilirubin is highly positively skewed (or skewed to the right).\n\n\n\n\n\nFigure 1.9: Histogram of age (left) and serum bilirubin (right) from PBC study data\n\n\n\n\n\n\n1.8.2 Boxplots\nAnother useful way to inspect the distribution of data is by using a box plot. In a box plot:\n\nthe line across the box shows the median value\nthe limits of the box show the 25-75% range (i.e. the inter-quartile range (IQR) where the middle 50% of the data lie)\nthe bars (or whiskers) indicate the most extreme values (highest and lowest) that fall within 1.5 times the interquartile range from each end of the box\n\nthe upper whisker is the highest value falling within 75th percentile plus 1.5 × IQR\nthe lower whisker is the lowest value falling within 25th percentile minus 1.5 × IQR\n\nany values in the dataset lying outside the whiskers are plotted individually.\n\nIf the data are symmetric, the line across the box (the median value) will be in the centre of the box, and the tails will be roughly equal.\nFigure 1.10 presents two boxplots from the PBC data: for age and serum bilirubin. We can see that the boxplot for age has roughly equal tails, and the median (the horizontal line) lies roughly in the middle of the interquartile range (the shaded box). It would be reasonable to assume that age follows a symmetric distribution from this plot. The boxplot for serum bilirubin shows a much longer upper tail, and a median much closer to the bottom of the shaded box than the middle. The boxplot also shows a number of points above the 75th percentile plus 1.5 × IQR. As the upper tail is longer than the lower tail, this distribution is positively skewed.\n\n\n\n\n\nFigure 1.10: Box plot of age (left) and serum bilirubin (right) from PBC study data"
  },
  {
    "objectID": "01-intro.html#how-to-report-summary-statistics",
    "href": "01-intro.html#how-to-report-summary-statistics",
    "title": "1  Introduction to statistics and presenting data",
    "section": "1.9 How to report summary statistics",
    "text": "1.9 How to report summary statistics\nWhen reporting summary statistics, it is important not to present results with too many decimal places. Doing so implies that your data have a higher level of precision than they do. For example, presenting a mean blood pressure of 100.2487 mmHg implies that blood pressure can be measured accurately to at least three decimal places.\nThere are a number of guidelines that have been written to help in the presentation of numerical data. Many of these guidelines are based on the number of decimal places, while others are based on the number of significant figures. Briefly, the number of significant figures are “the number of digits from the first non-zero digit to the last meaningful digit, irrespective of the position of the decimal point. Thus, 1.002, 10.02, 100200 (if this number is expressed to the nearest 100) all have four significant digits.” Armitage, Berry, and Matthews (2013)\nA summary of these guidelines that will be used in this course appear below.\n\n\n\n\nTable 1.6:  Guidelines for presentation of statistical results \n\nSummary statisticGuideline (reference)\n\nMeanIt is usually appropriate to quote the mean to one extra decimal place compared with the raw data. (Altman)\n\nMedian, Interquartile range, RangeAs medians, interquartile ranges and ranges are based on individual data points, these values should be presented with the same precision as the original data.\n\nPercentagePercentages do not need to be given with more than one decimal place at most. When the sample size is less than 100, no decimal places should be given. (Altman)\n\nStandard deviationThe standard deviation should usually be given to the same accuracy as the mean, or with one extra decimal place. (Altman)\n\nStandard errorAs per standard deviation\n\nConfidence intervalUse the same rule as for the corresponding effect size (be it mean, percentage, mean difference, regression coefficient, correlation coefficient or risk ratio) (Cole)\n\nTest statisticTest statistics should not be presented with more than two decimal places.\n\nP-valueReport p values to a single significant figure unless the p value is close to 0.05 (say, 0.01 – 0.2), in which case, report two significant figures. Do not report `not significant` for p values of 0.05 or higher. Very low p values can be reported as p < 0.001 or similar. A p value can indeed be 1, although some investigators prefer to report this as >0.9. (Assel)\n\nDifference in meansAs for the estimated means\n\nDifference in proportionsAs for the estimated proportions\n\nOdds ratio / Relative riskHazard and odds ratios are normally reported to two decimal places, although this can be avoided for high odds ratios (Assel)\n\nCorrelation coefficientOne or two decimal places, or more when very close to ±1   (Cole)\n\nRegression coefficientUse one more significant figure than the underlying data   (adapted from Cole)\n\n\n\n\n\nSources:\nAltman (1990)\nCole (2015)\nAssel et al. (2019)"
  },
  {
    "objectID": "01-intro.html#learning-outcomes",
    "href": "01-intro.html#learning-outcomes",
    "title": "1  Introduction to statistics and presenting data",
    "section": "Learning outcomes",
    "text": "Learning outcomes\nBy the end of these notes, you will be able to:\n\nnavigate the Stata interface\ninput and import data into Stata\nuse Stata menus to summarise data\nperform basic data transformations\nassign variable and value labels\nunderstand the difference between saving data and saving Stata output\ncopy Stata output to a standard word processing package"
  },
  {
    "objectID": "01-intro.html#introduction",
    "href": "01-intro.html#introduction",
    "title": "1  Introduction to statistics and presenting data",
    "section": "1.10 Introduction",
    "text": "1.10 Introduction\nStata is a powerful statistical package that is relatively easy to use. It is commonly used in health research, as well as in other fields such as econometrics and social science. The aim of these notes is to introduce the Stata environment, and to introduce the commands and procedures that are directly relevant to this course. There is much more to Stata that we will cover in these notes, and more information will be provided throughout the course."
  },
  {
    "objectID": "01-intro.html#part-1-a-simple-stata-analysis",
    "href": "01-intro.html#part-1-a-simple-stata-analysis",
    "title": "1  Introduction to statistics and presenting data",
    "section": "1.11 Part 1: A simple Stata analysis",
    "text": "1.11 Part 1: A simple Stata analysis\nIn this very brief section, we will introduce Stata by calculating the average of six ages. If you are using Windows, open Stata by clicking: Start > Stata 16 > Stata SE\nIf you are using MacOS, open Stata from the Applications folder. Note that while Stata is available for Windows and MacOS, most of the screenshots in these notes will be based on the Windows version.\nWhen you first open Stata, it will look something like the following.\n\n\n\n\n\n\n\n\n\nEach Stata session has a number of windows, which we will discuss later. For now, look in the top row of icons and find the icons that look like two grids: one with a pencil, and one with a magnifying glass: . Click the left icon, the one with the pencil. The following window will appear.\n\n\n\n\n\n\n\n\n\nThis window is known as the Data Editor, and is where data can be entered or changed. Enter the following six ages into Stata, starting at the top-left cell, by typing each number and then hitting Enter.\n20  25  23  29  21  27\nIf you make a mistake, simply click the incorrect cell, and enter the correct value. Your screen should look like this:\n\n\n\n\n\n\n\n\n\nThere are two things to note here:\n\nData in Stata are entered down a column. In Stata, columns represent variables, and rows represent observations. So our six observations of age are entered in one column.\nStata has given the name of var1 to our column of ages. We will fix this in a moment.\n\nClose the Data Editor window to return to the main Stata window. You will notice that the main Stata window now has some text that you might not understand. We will explain why shortly.\nLet’s rename our variable from var1 to age. There are a few ways you can do this in Stata, but one of the most convenient is to use the Variables Manager which can be accessed via Data > Variables Manager:\n\n\n\n\n\n\n\n\n\nThe Variables Manager is where you can change many variable properties, such as variable names or apply meaningful variable labels. Each variable is listed on a separate row, with aspects about each variable listed in the columns. To change the variable name, click var1 in the Name column. Notice that information about that variable appears to the right of the window, in the Variable properties section.\nIn the Name section within Variable properties, click var1 and replace it with age. Click Apply and notice that the variable’s name has been changed:\n\n\n\n\n\n\n\n\n\nClose the Variables manager window.\nSome important points about variable names in Stata: - any name you choose must be no more than 32 characters long; - variable names must contain only letters, numbers and the underscore (_); - variable names should start with a letter; - variable names are case-sensitive (so age, Age and AGE could represent three different variables)\nNow that we have entered our six ages, let’s calculate the mean age. Choose Statistics > Summaries, tables and tests > Summary and descriptive statistics > Summary statistics. The summarize dialog box will appear. From the Variables drop-down box, select age as below:\n\n\n\n\n\n\n\n\n\nClick OK, and the main Stata screen will appear as below.\n\n\n\n\n\n\n\n\n\nThe final text in the main window provides a summary of age: there are 6 observations, with a mean age of 24.2 years, a standard deviation of 3.49 years, a minimum of 20 and a maximum of 29 years.\n\n1.11.1 The Stata environment\nNow that we have seen a simple example of how to use Stata, let’s describe the Stata environment. The largest window in Stata is the Results window. This is where the results of your analyses appear, as well as any information, warnings or error messages. You may have noticed that the Results window also contains commands used to conduct analyses. For example, there is a command above summary output for age:\n. summarize age\nThis command is generated by Stata based on the entries in the summarize dialog box. Stata is inherently a command-driven program: the menus and dialog boxes simply generate commands that Stata interprets, and these commands (and their results) are included in the Results window. While most menu items and dialog boxes can be replicated using commands, it is easier to learn Stata using the menus and dialog boxes. In later Modules, we will include the commands that can be used as alternatives to using the Stata menus.\nThe Stata windows are summarised below.\n\n\n\n\n\n\n\nWindow\nPurpose\n\n\n\n\nResults\nShows your issued commands, results output (e.g. tables) and error messages or warnings.\n\n\nCommand\nWhere you can type in a command you want to run. The command window need not be used in this course\n\n\nVariables\nGives a list of the variables in your currently opened dataset.\n\n\nProperties\nShows the properties of your currently selected variable (selected from the Variables window) and of your currently opened dataset.\n\n\nHistory\nShows the history of your issued commands in your current session.\n\n\nData Editor (Edit)\nA separate window that allows you to edit or enter data.\n\n\nData Editor (Browse)\nA separate window that allows you to view data: data cannot be edited.\n\n\n\nStata allows you to perform most of your work by selecting options from the appropriate menus at the top of the main Stata window. A brief description of the main menu bar options follows.\nFile includes all the options you typically use in other programs, such as Open, Save, Exit. Note, that you can open or create various types of new files. The main type of file we open or create in this course is a Stata data file (.dta). In the Advanced Biostatistics and Statistical Computing course (PHCM9517), we will also use other file types such as a .do file for scripting (or writing) Stata commands.\nEdit includes the typical Copy, and Paste commands.\nData allows you to open the Data Editor. You can also create new variables and change current variables using Data > Create or change data.\nGraphics includes the commands to create various types of graphs including box plots, histograms, scatterplots, line graphs, and bar charts.\nStatistics includes all the commands to carry out statistical analyses and perform power and sample size calculations. Much of this course will focus on using commands located in this menu.\nUser is for saved files from other windows (e.g. saved graphs). You will not need to use this option in this course.\nWindow can be used to select which window you want to view (e.g. Results, Data Editor).\nHelp has many useful options including the viewing the PDF documentation, a Search function and other resources for using Stata. We will also demonstrate how to use helpful resources later in this introductory manual. Another useful Stata resource is the video tutorials produced by Stata: https://www.stata.com/links/video-tutorials/"
  },
  {
    "objectID": "01-intro.html#part-2-obtaining-basic-descriptive-statistics",
    "href": "01-intro.html#part-2-obtaining-basic-descriptive-statistics",
    "title": "1  Introduction to statistics and presenting data",
    "section": "1.12 Part 2: Obtaining basic descriptive statistics",
    "text": "1.12 Part 2: Obtaining basic descriptive statistics\nIn this exercise, we will analyse data to complete a descriptive table from a research study. The data come from a study in primary biliary cirrhosis, a condition of the liver, from Therneau and Grambsch (2010), Modeling Survival Data: Extending the Cox Model. By the end of this exercise, we will have completed the following table.\n\n\n\nSummary of 418 participants from the PBC study (Therneau and Grambsch, 2000)\n\nCharacteristic Summary\n\nAge (years)Mean (SD) or Median [IQR]\n\nSexMalen (%)\n\nFemalen (%)\n\nAST* (U/ml)Mean (SD) or Median [IQR]\n\nSerum bilirubinMean (SD) or Median [IQR]\n\nStageIn (%)\n\nIIn (%)\n\nIIIn (%)\n\nIIIVn (%)\n\nVital status at study endAlive: no transplantn (%)\n\nAlive: transplantn (%)\n\nDeceasedn (%)\n\n* asparate aminotransferase\n\n\n\n\nThis table is available in Table1.docx, saved on Moodle.\n\n1.12.1 Opening a Stata data file\nTyping data directly into Stata is not common; we usually open data that have been saved as a Stata data file, or import data that have been entered into another package. Here, we will open a dataset that has been stored as a Stata data file (which has the .dta suffix).\n\nLocate the data set called pbc.dta on Moodle. Click the file to download it, and then save it in a folder you will be able to locate later - for example, your OneDrive folder. The description of this dataset (i.e. the metadata) have been saved as a plain text file: pbc_info.txt\nIn Stata, choose File > Open. Browse to where you stored the dataset and click Open.\nYou may get an error: “Data in memory have changed”. This means that you have not saved a copy of your current data, and by importing a new dataset, your changes will be lost. As Stata can only open one set of data at a time, you can choose to: Save your current data, Don’t Save your current data, or Cancel. We don’t need to save the data from our simple analysis (the six ages), so we can choose Don’t Save.\n\nAfter opening the data successfully, there will be 418 rows of data, and 20 variables. Examine the pbc_info.txt file for a description of each variable.\n\n\n1.12.2 Assigning variable labels\nAs we saw earlier, Stata has specific rules about variable names. Variable labels can be used to obtain more descriptive output. For example, the variable entered as bili can be labelled “Serum bilirubin (mg/dl)”.\nTo apply a variable label, open the Variables Manager: Data > Variables Manager. Here we can click the variable to be labelled, and enter the new variable label and click Apply:\n\n\n\n\n\n\n\n\n\nThe variable label will now be used in place of the variable name in most output:\n\n. summarize bili, detail\n\n                   Serum bilirubin (mg/dl)\n-------------------------------------------------------------\n      Percentiles      Smallest\n 1%           .4             .3\n 5%           .5             .3\n10%           .6             .3       Obs                 418\n25%           .8             .4       Sum of Wgt.         418\n\n50%          1.4                      Mean           3.220813\n                        Largest       Std. Dev.      4.407506\n75%          3.4           22.5\n90%          8.1           24.5       Variance       19.42611\n95%           14           25.5       Skewness       2.707849\n99%         21.6             28       Kurtosis       10.95486\n\nTASK: Assign meaningful variable labels to the variables used in Table 1.\n\n\n1.12.3 Summarising continuous variables\nAs we saw in Part 1, continuous variables can be summarised using Statistics > Summaries, tables and tests > Summary and descriptive statistics > Summary statistics. There are three continuous variables that we would like to summarise: age, AST and serum bilirubin. Each of these can be listed in the summarize dialog box, as shown below.\n\n\n\n\n\n\n\n\n\nBy default, the summarize command calculates the mean, standard deviation, minimum and maximum. We may be interested in obtaining the median and interquartile ranges, so we select the Display additional statistics option:\n\n\n\n\n\n\n\n\n\nSummary statistics are produced for each of the three variables. We will use describe the output for age:\n\n\n\n\n\n\n\n\n\nThe output for a detailed summary in Stata should be read as three separate columns. The right-most column lists the number of observations, the mean and standard deviation and other numeric statistics. The left-most column contains the Percentiles: median (50%), lower quartile (25%) and upper quartile (75%). The middle column lists the four smallest and four largest observations, so that we can assess whether the smallest and largest observations are plausible.\nFor each of our three continuous variables, we need to decide whether to present the mean and standard deviation, or the median and interquartile range. This decision can be made after examining a histogram and boxplot for each variable.\n\n\n1.12.4 Producing a histogram\nTo produce a histogram, go to menu Graphics > Histogram. Choose the variable to be plotted in the Variable box, and choose the Frequency radio button so that a frequency histogram is produced. Note that only one variable can be plotted at a time, so this procedure will need to be repeated for each continuous variable.\n\n\n\n\n\n\n\n\n\nThe default histogram for age appears below.\n\n\n\n\n\n\n\n\n\nStata will automatically choose the number of bins and the width of each bin, however these decisions may not always produce the most optimal histogram. These options can be altered by defining either: the number of bins, or the bin width (but not both); and/or the lower limit of the first bin.\nLooking at the command window, Stata has used the following parameters to define the histogram: bin=20, start=26.277892, width=2.6080767. This means that Stata has chosen 20 bins to represent the data, with the first bin starting at 26.2 years and each bin representing 2.6 years. A more easily read histogram might have a bin-width of 5, starting at 25 years of age, so that age categories represent 25 to less than 30, 30 to less than 35 etc, as defined below:\n\n\n\n\n\n\n\n\n\nThis results in a histogram with fewer bars and more sensible cut-points: ::: {.cell} ::: {.cell-output-display}  ::: :::\n\n\n1.12.5 Producing a boxplot\nThe boxplot dialog box is similar to the histogram dialog box. While it is possible to specify more than one variable to be plotted, this is not recommended when variables are measured on very different scales as all variables are plotted on a chart with the same scale.\nTASK: Obtain histograms and boxplots for age, AST and bilirubin. Based on these plots, decide whether the mean or the median is the appropriate summary to use for each variable. Transfer your summary statistics to Table 1.\n\n\n1.12.6 Producing a one-way frequency table\nWe have three categorical variables to summarise in Table 1: sex, stage and vital status. These variables are best summarised using one-way frequency tables.\nChoose Statistics > Summaries, tables, and tests > Frequency tables > One-way table. Choose the variable to be summarised as the Categorical variable, and leave all other options unchanged:\n\n\n\n\n\n\n\n\n\nClick OK to obtain the following table:\n\n        sex |      Freq.     Percent        Cum.\n------------+-----------------------------------\n          1 |         44       10.53       10.53\n          2 |        374       89.47      100.00\n------------+-----------------------------------\n      Total |        418      100.00\n\n\n\n1.12.7 Assigning value labels to categorical variables\nYou will notice that the table above, in its current form, is uninterpretable as the 1 and 2 categories are not labelled. In this course, all variables including categorical variables are numerically coded. This is because “string” or “character” variables (e.g. entered as “male” or “female”) cannot be used in many of the analysis commands of Stata. Instead, we use numerical codes and assign labels to the categories.\nThere are two parts to applying value labels to categorical variables: 1) defining the labels, and 2) applying the labels to a variable. This may seem cumbersome, but there are times where we can apply value labels to a collection of variables (for example, multiple variables comprising yes/no categories, or Likert scales such as: strongly disagree, disagree, neutral, agree, strongly agree). Both parts can be done within the Variables Manager.\nPart 1: Defining the value labels\n\nOpen the Variables Manager: Data > Variables Manager and select the variable you want to assign labels to (in this case, sex). You will see that the Value label in the Properties section is blank. To create a value label, click Manage.\n\nAlternatively, choose Data > Data utilities > Label utilities > Manage value labels.\n\n\n\n\n\n\n\n\n\nIn the Manage value labels dialog box, click the Create label button.\n\nIn the next dialog box, enter a name for the value label such as sex_label in the Label name: box. You can use the same name of the variable for the label, or choose a different name. Note: as for variables, the value label name is case-sensitive.\nNext, we specify what each category (i.e. 1 and 2) represents. By checking the metadata document, we see that 1 represents “Male” and 2 represents “Female”. Type the number 1 in the Value: box and the word Male in the Label: box; then click the Add button. Then type the number 2 in the Value: box and the word Female in the Label: box; click the Add button again. The defined value labels for males and females should appear in the box on the left-hand side. When you are done, click the OK button.\n\n\n\n\n\n\n\n\n\n\nYou will be returned to the Manage value labels dialog box, which will now have a record for sex_label. By clicking the arrow next to the label name, you will see the codes that you have defined:\n\n\n\n\n\n\n\n\n\nAt this point, you can close the Manage value labels dialog box by clicking Close.\nPart 2: Applying the value labels to a variable\nNow that the labels are defined, we need to attach them to the relevant variables. Within the Variables Manager, click the variable to be labelled (here, sex). The previously defined label can be assigned to this variable by clicking the Value label drop-down menu, and choosing the appropriate label (here, sex_label), and clicking Apply:\n\n\n\n\n\n\n\n\n\nAlternatively, go to Data > Data utilities > Label utilities > Assign value label to variables. Select sex from the Variables: dropdown box, and select sex_label from the Value label: dropdown box. Click OK.\n\n\n\n\n\n\n\n\n\nThere are a number of ways that we can confirm that the labelling has been done correctly. One of the easiest ways is to use the codebook command to investigate the coding of sex: Data > Describe data > Describe data contents (codebook).\n\n. codebook sex\n\n----------------------------------------------------------------------------------------\nsex                                                                          (unlabeled)\n----------------------------------------------------------------------------------------\n\n                  type:  numeric (long)\n                 label:  sex_label\n\n                 range:  [1,2]                        units:  1\n         unique values:  2                        missing .:  0/418\n\n            tabulation:  Freq.   Numeric  Label\n                            44         1  Male\n                           374         2  Female\n\nHere we can see that the codes for male and female have been applied correctly. We can also examine the Data Browser and confirm that sex has been labelled.\nNote: If you want to see the original coded values of the labelled groups in the Data Browser window, you can hide the value labels by choosing Tools > Value labels > Hide all value labels for Windows, or View > Value labels > Hide all value labels for Mac from the menu bar in the Data Browser window.\nTASK: create and apply value labels for Vital Status.\nNow that our categorical variables are labelled, we can produce the one-way frequency tables. As before, choose Statistics > Summaries, tables, and tests > Frequency tables > One-way table. Our newly labelled table for sex appears as below.\n\n        sex |      Freq.     Percent        Cum.\n------------+-----------------------------------\n       Male |         44       10.53       10.53\n     Female |        374       89.47      100.00\n------------+-----------------------------------\n      Total |        418      100.00\n\nTASK: produce one-way frequency tables for the other categorical variables in Table 1 (stage and vital status).\n\n\n1.12.8 Producing a two-way frequency table\nTo produce tables summarising two categorical variables, go to Statistics - Summaries, tables, and tests - Frequency tables - Two-way table with measures of association.\nTo produce a two-way table showing stage of disease by sex using the pbc.dta data, do the following. In the tabulate2 – two way table with measures of association dialog box, select the variable sex as the Row variable:, and stage as the Column variable: as shown below.\n\n\n\n\n\n\n\n\n\nClick OK to obtain the output below.\n\n. tabulate sex stage\n\n           |                    stage\n       sex |   Stage 1    Stage 2    Stage 3    Stage 4 |     Total\n-----------+--------------------------------------------+----------\n      Male |         3          8         16         17 |        44 \n    Female |        18         84        139        127 |       368 \n-----------+--------------------------------------------+----------\n     Total |        21         92        155        144 |       412 \n\nYou may notice in the above that the number of observations is now 412. This is because there are missing observations for either sex or stage: which is it, and how would you determine this?\nFrom the cross-tabulation, you can see the individual frequencies of participants in each of the categories in each cell. For example, there are 3 male participants who have Stage 1 disease. You can also read the totals for each row and column. For example, there are 44 males, and 144 participants have Stage 4 disease.\nYou can also add percentages into your table. For example, in the tabulate2 – two way table with measures of association dialog box tick the box Within-column relative frequencies for separate percentages of sex within each stage.\n\n. tabulate sex stage, column\n\n+-------------------+\n| Key               |\n|-------------------|\n|     frequency     |\n| column percentage |\n+-------------------+\n\n           |                    stage\n       sex |   Stage 1    Stage 2    Stage 3    Stage 4 |     Total\n-----------+--------------------------------------------+----------\n      Male |         3          8         16         17 |        44 \n           |     14.29       8.70      10.32      11.81 |     10.68 \n-----------+--------------------------------------------+----------\n    Female |        18         84        139        127 |       368 \n           |     85.71      91.30      89.68      88.19 |     89.32 \n-----------+--------------------------------------------+----------\n     Total |        21         92        155        144 |       412 \n           |    100.00     100.00     100.00     100.00 |    100.00 \n\nWe can see that the 3 male participants with Stage 1 disease made up 14% of those with Stage 1 disease.\n\n\n1.12.9 Saving data from Stata\nNow that you have made some changes to the pbc data, it is good practice to save the dataset. Stata uses its own file format to save data. Data saved from Stata will end with the .dta suffix, and will contain useful information such as variable labels and value labels, as well as any new variables created. However, data saved by Stata will only be able to be opened by Stata - you will not easily be able to share your data with colleagues who do not have Stata. To save a Stata dataset, choose File > Save.\nIf you want to share data with colleagues who do not have Stata, you can use File > Export to save your data in another file format (recognising that variable and value labels will not be exported.)\n\n\n1.12.10 Copying output from Stata\nIt is important to note that saving data in Stata will not save your output. Stata data and output are completely separate to one another. The easiest way to retain the output of your analyses is to copy the output into a word processor package (e.g. Microsoft Word) before closing Stata. Once Stata is closed, all the output (that is, all your hard work!) is lost.\nTo copy output from Stata, you can select the output and choose Edit > Copy. This will copy the output as plain text for pasting into a Word document. If you select a single table for copying, you can also Copy table or Copy table as HTML. Whichever way you copy output into Word, you will need to make sure you reformat the table and relabel your header row and column properly for your assignments as described in Module 1. Alternatively, you can copy with the Copy table option for pasting into an Excel worksheet and reformat your table in Excel before pasting into Word.\nCopying output from Stata can get a little complicated to explain. We have included a video on Moodle to summarise the different ways output can be copied.\nTASK: complete Table 1 using the output generated in this exercise. You should decide on whether to present continuous variables by their means or medians, and present the most appropriate measure of spread. Include footnotes to indicate if any variables contain missing observations."
  },
  {
    "objectID": "01-intro.html#part-3-creating-other-types-of-graphs",
    "href": "01-intro.html#part-3-creating-other-types-of-graphs",
    "title": "1  Introduction to statistics and presenting data",
    "section": "1.13 Part 3: Creating other types of graphs",
    "text": "1.13 Part 3: Creating other types of graphs\n\n1.13.1 Bar graphs\nHere we will create the bar chart shown in Figure 1.4 using the pbc.dta dataset. The x-axis of this graph will be the stage of disease, and the y-axis will show the number of participants in each category.\nTo create a Bar chart, go to the Stata menu Graphics > Bar chart and the bar-chart dialog box will appear.\n\n1.13.1.1 Simple bar graph\nFor most of our bar graphs, we will be plotting frequencies, so we choose Graph of frequencies within categories\n\n\n\n\n\n\n\n\n\nFor a simple bar graph, go to the Categories tab, tick the Group 1 box and choose stage as your first grouping variable:\n\n\n\n\n\n\n\n\n\nClick the Y axis tab to include a more meaningful label for the y axis:\n\n\n\n\n\n\n\n\n\nClick Submit or OK, and the following graph will appear:\n\n\n\n\n\n\n\n\n\nNote: Value labels have been assigned to stage to create more meaningful output, and bar colours have been changed to allow for grey-scale printing.\n\n\n\n1.13.2 Submit vs OK button\nYou may note that most dialog boxes in Stata have two choices: the Submit button, and the OK button. Both buttons will submit the command to be run, and both will produce a graph. The Submit button will submit the command but leave the dialog box open, while the OK button will submit the command and close the dialog box. Given the building a graph often involves many incremental changes, the Submit button is a useful option.\n\n\n1.13.3 Clustered bar graph\nTo create a clustered bar chart as shown in Figure 1.5, go to: Graphics > Bar chart again. With the previous settings in place (i.e. stage as grouping variable and with appropriate axes labels), now choose sex as the Group 1 variable, and tick Group 2 and choose stage as the second grouping variable.\n\n\n\n\n\n\n\n\n\nIn the Options tab, tick Treat first category grouping as y variables. When you are done, click OK or Submit.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn a clustered bar chart, the Group 2 variable is the main variable grouping (here, stage), and each of the Group 2 categories is split by the Group 1 variable (here, sex).\n\n\n1.13.4 Stacked bar graph\nTo create a stacked bar chart shown in Figure 1.6, bring up the Bar chart dialog box, go to the Options tab and tick Stack bars on y variables.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.13.5 Stacked bar graph of relative frequencies\nIf one wants to compare the sex distribution across the stage categories, it would be convenient if all the bars have the same height (100%). To generate such a bar chart in Stata, tick Base bar heights on percentages in the Options tab of the Bar charts dialog box. Change the y-axis title in the Y axis tab to Percentage of students in each age group.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.13.6 Editing graphs in Stata\nThere are two main approaches of editing many aspects of a graph (such as colours, labels, font-size etc). The first approach is to use options within the dialog boxes. For example, if we wanted to use a grey-and-white colour scheme for Figure X, we can define the colours of the bars in the Bars tab of the bar chart dialog box.\nHere, we will define Bar 1 to be White:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBar 2 can be defined to be Gray, resulting in the graph below:\n\n\n\n\n\n\n\n\n\nThe second approach to customising graphs is to use the Graph Editor. Each Stata graph window includes a Graph Editor button:\n\n\n\n\n\nGraph editor button on Stata for Windows\n\n\n\n\n\n\n\n\n\nGraph editor button on Stata for MacOS\n\n\n\n\nThe Graph Editor window comprises two main sections: the graph that can be edited on the left, and a list of elements of the graph on the right. Most aspects of a graph’s appearance can be edited in the Graph Editor, usually by double-clicking an element (e.g. a bar, or a bar segment) and changing its properties. There are too many ways to change a graph’s appearance to document here: feel free to explore and experiment!\n\n\n\n\n\nGraph editor window: Windows\n\n\n\n\n\n\n\n\n\nGraph editor window: MacOS\n\n\n\n\nWhen you are done editing in the Graph Editor, click the Graph Editor icon again to stop the Graph Editor. You will be prompted to save your graph. You can click the Save button, choose Save as and choose to save using the PNG (*.png) format. You can then insert your saved PNG file into your word processing package as usual.\n\n\n1.13.7 Creating line graphs\nTo demonstrate the graphing of aggregate data with Stata, we use the data on new cases and deaths from prostate cancer in males in NSW. This data has been entered into Stata as Example_1.2.dta.\nIf you look at the data in the Data Editor window, you will see that there are 20 rows - a row for each year of data. Each row contains the number of new cases (NCases), number of deaths (NDeaths), the incidence rate (RCases) and death rate (RDeaths).\nTo create a line graph as in Figure 1.7 select Graphics > Twoway graph (scatter, line, etc.) and click the Create… button in the twoway – Twoway graphs dialog box to bring up a dialog box for defining Plot 1.\n\n\n\n\n\n\n\n\n\nChoose Line as the plot type, rcases as the Y variable and year as the X variable as shown below.\n\n\n\n\n\n\n\n\n\nClick Accept, and then click Submit to check how the graph looks.\n\n\n\n\n\n\n\n\n\nThis looks ok, but we want to add the death rate to the plot. Click Create… again and add a Plot 2 for mortality rate:\n\n\n\n\n\n\n\n\n\nChoose Line as the plot type again, rdeaths as the Y variable and year as the X variable. Click Accept, and then Submit to check how the graph looks like now. You should see both variables plotted:\n\n\n\n\n\n\n\n\n\nTo change the format of either line, click the relevant plot definition in the main twoway dialog box and click Edit. Click the Line properties button and choose a Pattern (e.g. Short-dash), then click Submit again.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNext, we need an appropriate label for the y-axis. In the main twoway dialog box, click on the Y axis tab and label the title appropriately (e.g. Age-standardardised rate and then click OK or Submit. The graph below should be produced.\n\n\n\n\n\n\n\n\n\n[Command: twoway (line rcases year) (line rdeaths year, lpattern(shortdash)), ytitle(Age-standardised rate)]"
  },
  {
    "objectID": "01-intro.html#learning-outcomes-1",
    "href": "01-intro.html#learning-outcomes-1",
    "title": "1  Introduction to statistics and presenting data",
    "section": "Learning outcomes",
    "text": "Learning outcomes\nBy the end of this Module, you will be able to:\n\nunderstand the difference between R and RStudio\nnavigate the RStudio interface\ninput and import data into R\nuse R to summarise data\nperform basic data transformations\nunderstand the difference between saving R data and saving R output\ncopy R output to a standard word processing package"
  },
  {
    "objectID": "01-intro.html#part-1-an-introduction-to-r",
    "href": "01-intro.html#part-1-an-introduction-to-r",
    "title": "1  Introduction to statistics and presenting data",
    "section": "1.14 Part 1: An introduction to R",
    "text": "1.14 Part 1: An introduction to R\n“R is a language and environment for statistical computing and graphics.” Link. It is an open-source programming language, used mainly for statistics (including biostatistics) and data science.\nThe aim of these notes is to introduce the R language within the RStudio environment, and to introduce the commands and procedures that are directly relevant to this course. There is so much more to R than we can cover in these notes. Relevant information will be provided throughout the course, and we will provide further references that you can explore if you are interested.\n\n1.14.1 R vs RStudio\nAt its heart, R is a programming language. When you install R on your computer, you are installing the language and its resources, as well as a very basic interface for using R. You can write and run R code using the basic R app, but it’s not recommended.\nRStudio is an “Integrated Development Environment” that runs R while also providing useful tools to help you write code and analyse data. You can think of R as an engine which does the work, and RStudio as a car that uses the engine, but also provides useful tools like GPS navigation and reversing cameras that help you drive.\nNote: even though we recommend that you use RStudio, you still need install R. RStudio will not run without R installed.\nIn summary, we recommend you use RStudio to write R code.\n\n\n1.14.2 Installing R and RStudio\n\n1.14.2.1 To install R on your computer\n\nDownload the R installer from:\n\nfor Windows: https://cran.r-project.org/bin/windows/base/\nfor MacOS: https://cran.r-project.org/bin/macosx/\n\n\nNote for Windows users: as at May 27, 2022, R Version 4.2.0 has compatability issues with RStudio. You should download and install R from https://cran.r-project.org/bin/windows/base/rpatched.html\n\nInstall R by running the installer and following the installation instructions. The default settings are fine.\n\nNote for macOS: if you are running macOS 10.8 or later, you will need to install an additional application called XQuartz, which is available at https://www.xquartz.org/. Download the latest installer (XQuartz-2.8.1.dmg as of April 2022), and install it in the usual way.\n\nOpen the R program. You should see a screen as below:\n\n\n\n\n\n\nNear the bottom of the R screen, you will find the “>” symbol which represents the command line. If you type 1 + 2 into the command line and then hit enter you should get:\n[1] 3\nThis is R performing your calculation, with the [1] indicating that the solution to 1 + 2 is a single number (the number 3).\nAt this point, close R - we will not interact with R like this in the future. You can close R by typing quit() at the command prompt, followed by the return key, or in the usual way of closing an application in your operating system. There is no need to save anything here if prompted.\n\n\n1.14.2.2 To install RStudio on your computer\n\nMake sure you have already installed R, and verified that it is working.\nDownload the RStudio desktop installer at: https://www.rstudio.com/products/rstudio/download. Ensure that you select the RStudio Desktop (Free) installer in the first column.\nInstall RStudio by running the installer and following the installation instructions. The default settings are fine.\nOpen RStudio, which will appear as below:\n\n\n\n\n\n\nLocate the command line symbol “>” at the bottom of the left-hand panel. Type 1 + 2 into the command line and hit enter, and you will see:\n[1] 3\nThis confirms that RStudio is running correctly, and can use the R language to correctly calculate the sum between 1 and 2!\nRStudio currently comprises three window panes, and we will discuss these later.\n\n\n\n\n\n\nTASK\n\n\n\nInstall R and RStudio and confirm they are both working correctly.\n\n\n\n\n\n1.14.3 Recommended setup\nI will provide a recommended setup for R and RStudio in this section. You are free to use alternative workflows and setup, but this setup works well in practice.\n\n1.14.3.1 RStudio preferences\nBy default, RStudio will retain data, scripts and other objects when you quit your RStudio session. Relying on this can cause headaches, so I recommend that you set up RStudio so that it does not preserve your workspace between sessions. Open the RStudio options:\n\nMac: RStudio > Preferences\nWindows: Tools > Options\n\nand deselect “Restore .RData into workplace at startup”, and choose: “Save workspace to .RData on exit: Never”.\n\n\n\n\n\n\n\n1.14.3.2 Set up a project\nA project in RStudio is a folder that RStudio recognises as a place to store R scripts, data files, figures that are common to an analysis project. Setting up a folder allows much more simple navigation and specification of data files and output. More detail can be found in Chapter 8 of the excellent text: R for Data Science. Using projects is not necessary, but I recommend working with projects from day one.\nWe will create a project called PHCM9795 to store all the data you will use and scripts that you will write in this course. First, think about where you want to store your project folder: this could be somewhere in your Documents folder.\nStep 1: Choose File > New Project… in RStudio to open the Create Project dialog box:\n\n\n\n\n\nStep 2: Click the first option to create a project in a New directory\n\n\n\n\n\nStep 3: Click the first option: New Project. Give the project a name, by typing PHCM9795 in the “Directory name”, and choose where you want to store the project by clicking the Browse button.\n\n\n\n\n\nStep 4: Click Create to create your project.\nYou will now have a new folder in your directory, which contains only one file: PHCM9795.Rproj, and the two right-hand panes of RStudio will appear as below:\n\n\n\n\n\n\n\n\n\n\n\nTASK\n\n\n\nCreate a new project called PHCM9795.\n\n\nThe top-right menu bar is showing that you are working within the PHCM9795 project, and the bottom-right window is showing the contents of that window: the single PHCM9795.Rproj file. We will add some more files to this project later.\n\n\n\n1.14.4 A simple R analysis\nIn this very brief section, we will introduce R by calculating the average of six ages.\nTo begin, open a new R Script by choosing File > New file > R Script . A script (or a program) is a collection of commands that are sequentially processed by R. You can also type Ctrl+Shift+N in Windows, or Command+Shift+N in MacOS to open a new script in RStudio, or click the New File button at the top of the RStudio window.\nYou should now see four window panes, as below. In the top-left window, type the following (replacing my name with yours, and including today’s date):\n\n# Author: Timothy Dobbins\n# Date: 5 April 2022\n# Purpose: My first R script\n\nage <- c(20, 25, 23, 29, 21, 27)\nsummary(age)\n\nNote: R is case-sensitive, so you should enter the text exactly as written in these notes.\nYour screen should look something like:\n\n\n\n\n\nTo run your script, choose Code > Run Region > Run All. You will see your code appear in the bottom-left window, with the following output:\n\n> # Author: Timothy Dobbins\n> # Date: 5 April 2022\n> # Purpose: My first R script\n> \n> age <- c(20, 25, 23, 29, 21, 27)\n\n> summary(age)\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  20.00   21.50   24.00   24.17   26.50   29.00 \n\nWe will explain the key parts of this script later, but for now, you have entered six ages and calculated the mean age (along with five other summary statistics).\n\n\n\n\n\n\nTASK\n\n\n\nType the code above into the top-left window, and run the script.\nSave your script within the PHCM9795 project by using File > Save As, using the name my_first_analysis.R.\n\n\n\n\n1.14.5 The RStudio environment\nNow that we have seen a simple example of how to use R within RStudio, let’s describe the RStudio environment. Let’s assume that you have just run your first R script, and you have four windows as below:\n\n\n\n\n\nThe top-left window is call the Source window, and is where you write and edit your R scripts. Scripts can be saved by clicking File > Save As or by clicking on the symbol of a floppy disk at the top of the script. The file will have an extension of .R, for example script.R. Remember to give your script a meaningful title and remember to periodically save as you go.\nIn RStudio, the name of the script will be black when it has been saved, and will change to red if you have any unsaved changes.\nThe Console window, at the bottom left, contains the command line which is indicated with the symbol >. You can type commands here, but anything executed directly from the console is not saved and therefore is lost when the session ends (when you exit RStudio). You should always run your commands from a script file which you can save and use again later. When you run commands from a script, the output and any notes/errors are shown in the console. The Terminal and Jobs tabs will not be used in this course.\nThe Environment window at the top-right shows a list of objects that have been created during your session. When you close your RStudio session these objects will disappear. We will not use the History or Connections tabs in this course.\nThe bottom right corner contains some useful tabs, in particular the Help tab. When you are troubleshooting errors or learning how to use a function, the Help tab should be the first place you visit. Here you can search the help documents for all the packages you have installed. Whenever you create plots in R, these will be shown in the Plots tab. The Packages tab contains a list of installed packages and indicates which ones are currently in use (we will learn about packages later). Packages which are loaded, i.e. in use, are indicated with a tick. Some packages are in use by default when you begin a new session. You can access information about a package by clicking on its name. The Files tab provides a shortcut to access your files. The Viewer tab will not be used in this course.\n\n\n1.14.6 Some R basics\nWhile we use R as a statistics package, R is a programming language. In order to use R effectively, we need to define some basics.\n\n1.14.6.1 Scripts\nWhile R can be run completely from the command line, issuing commands one-by-one, it is most commonly run using scripts. A script is simply a list of commands that are processed in order. The simple analysis we conducted earlier is a very simple script. Some things to know about R scripts:\n\nanything appearing after a # is a comment, and is ignored by R. The first three lines of our script are there for ourselves (either as writers of code, or readers of code). I include comments at the beginning of each of my scripts to describe:\n\nwho wrote the script (useful if someone else uses your script and wants to ask questions about it);\nwhen the script was written;\nwhat the script does. This last point may seem odd, but it’s useful to describe what this script does, and why it might differ to other scripts being used in the analysis. This is particularly useful if your scripts become long and complex.\n\nR is case-sensitive. So age, AGE and Age could refer to three separate variables (please don’t do this!)\nuse blank lines and comments to separate sections of your script\n\n\n\n1.14.6.2 Objects\nIf you do some reading about R, you may learn that R is an “object-oriented programming language”. When we enter or import data into R, we are asking R to create objects from our data. These objects can be manipulated and transformed by functions, to obtain useful insights from our data.\nObjects in R are created using the assignment operator. The most common form of the assignment operator looks like an arrow: <- and is typed as the < and - symbols. The simplest way of reading <- is as the words “is defined as”. Note that it possible to use -> and even = as assignment operators, but their use is less frequent.\nLet’s see an example:\n\nx <- 42\n\nThis command creates a new object called x, which is defined as the number 42 (or in words, “x is defined as 42”). Running this command gives no output in the console, but the new object appears in the top-right Environment panel. We can view the object in the console by typing its name:\n\n# Print the object x\nx\n\n[1] 42\n\n\nNow we see the contents of x in the console.\nThis example is rather trivial, and we rarely assign objects of just one value. In fact, we created an object earlier, called age, which comprised six values.\n\n\n1.14.6.3 Data structures\nThere are two main structures we will use to work with data in this course: vectors and data frames. A vector is a combination of data values, all of the same type. For example, our six ages that we entered earlier is a vector. You could think of a vector as a column of data (even though R prints vectors as rows!) And technically, even an object with only one value is a vector, a vector of size 1.\nThe easiest way of creating a vector in R is by using the c() function, where c stands for ‘combine’. In our previous Simple Analysis in R (Section 1.14.4), we wrote the command:\n\nage <- c(20, 25, 23, 29, 21, 27)\n\nThis command created a new object called age, and combined the six values of age into one vector.\nJust as having a vector of size 1 is unusual, having just one column of data to analyse is also pretty unusual. The other structure we will describe here is a data frame which is essentially a collection of vectors, each of the same size. You could think of a data frame as being like a spreadsheet, with columns representing variables, and rows representing observations.\nThere are other structures in R, such as matrices and lists, which we won’t discuss in this course. And you may come across the term tibble, which is a type of data frame.\n\n\n1.14.6.4 Functions\nIf objects are the nouns of R, functions are the verbs. Essentially, functions transform objects. Functions can transform your data into summary statistics, graphical summaries or analysis results. For example, we used the summary() function to display summary statistics for our six ages.\nR functions are specified by their arguments (or inputs). The arguments that can be supplied for each function can be inspected by examining the help notes for that function. To obtain help for a function, we can submit help(summary) (or equivalently ?summary) in the console, or we can use the Help tab in the bottom-right window of RStudio. For example, the first part of the help notes for summary appear as:\n\n\n\n\n\nThe help notes in R can be quite cryptic, but the Usage section details what inputs should be specified for the function to run. Here, summary requires an object to be specified. In our case, we specified age, which is our object defined as the vector of six ages.\nMost help pages also include some examples of how you might use the function. These can be found at the very bottom of the help page.\n\n\n\n\n\nThe summary() function is quite simple, in that it only requires one input, the object to be summarised. More complex functions might require a number of inputs. For example, the help notes for the descriptives() function in the jmv package show a large number of inputs can be specified:\n\n\n\n\n\nThere are two things to note here. First, notice that the first two inputs are listed with no = symbol, but all other inputs are listed with = symbols (with values provided after the = symbol). This means that everything apart from data and vars have default values. We are free to not specify values for these inputs if we are happy with the defaults provided. For example, by default the variance is not calculated (as variance = FALSE). To obtain the variance as well as the standard deviation, we can change this default to variance = TRUE:\n\n# Only the standard deviation is provided as the measure of variability\ndescriptives(data=pbc, vars=age)\n\n# Additionally request the variance to be calculated\ndescriptives(data=pbc, vars=age, variance=TRUE)\n\nSecond, for functions with multiple inputs, we can specify the input name and its value, or we can ignore the input name and specify just the input values in the order listed in the Usage section. So the following are equivalent:\n\n# We can specify that the dataset to be summarised is pbc,\n#   and the variable to summarise is age:\ndescriptives(data=pbc, vars=age)\n\n# We can omit the input name, as long as we keep the inputs in the correct order - \n#   that is, dataset first, variable second:\ndescriptives(pbc, age)\n\n# We can change the order of the inputs, as long as we specify the input name:\ndescriptives(vars=age, data=pbc)\n\nIn this course, we will usually provide all the input names, even when they are not required. As you become more familiar with R, you will start to use the shortcut method.\n\n\n1.14.6.5 The curse of inconsistency\nAs R is an open-source project, many people have contributed to its development. This has led to a frustrating part of R: some functions require a single object to be specified, but some require you to specify a data frame and select variables for analysis. Let’s see an example.\nThe help for summary() specifies the usage as: summary(object, ...). This means we need to specify a single object to be summarised. An object could be a single column of data (i.e. a vector), or it could be a data frame. If we have a data frame called pbc which contains many variables, the command summary(pbc) would summarise every variable in the data frame.\nWhat if we only wanted to summarise the age of the participants in the data frame? To select a single variable from a data frame, we can use the following syntax: dataframe$variable. So to summarise just age from this data frame, we would use: summary(pbc$age).\nCompare this with the descriptives() function in the jmv package. We saw earlier that the two required inputs for descriptives() are data (the data frame to be analysed) and vars (the variables to be analysed). So to summarise age from the pbc data frame, we would specify descriptives(data=pbc, vars=age).\nThis inconsistency will seem maddening at first, and will continue to be maddening! Reading the usage section of the help pages is a useful way to determine whether you should specify an object (like pbc$age) or a data frame and a list of variables.\n\n\n\n1.14.7 Packages\nA package is a collection of functions, documentation (and sometimes datasets) that extend the capabilities of R. Packages have been written by R users to be freely distributed and used by others. R packages can be obtained from many sources, but the most common source is CRAN: the Comprehensive R Archive Network.\nA useful way of thinking about R is that R is like a smartphone, with packages being like apps which are downloaded from CRAN (similar to an app-store). When you first install R, it comes with a basic set of packages (apps) installed. You can do a lot of things with these basic packages, but sometimes you might want to do things differently, or you may want to perform some analyses that can’t be done using the default packages. In these cases, you can install a package.\nLike installing an app on a smartphone, you only need to install a package once. But each time you want to use the package, you need to load the package into R.\n\n1.14.7.1 How to install a package\nThere are a couple of ways to install a package. You can use the install.packages() function if you know the exact name of the package. Let’s use an example of installing the skimr package, which gives a very nice, high-level overview of any data frame. We can install skimr by typing the following into the console:\n\ninstall.packages(\"skimr\")\n\nNote the use of the quotation marks.\nAlternatively, RStudio offers a graphical way of installing packages that can be accessed via Tools > Install Packages, or via the Install button at the top of the Packages tab in the bottom-right window. You can begin typing the name of the package in the dialog box that appears, and RStudio will use predictive text to offer possible packages:\n\n\n\n\n\nWhile writing code is usually the recommended way to use R, installing packages is an exception. Using Tools > Install Packages is perfectly fine, because you only need to install a package once.\n\n\n1.14.7.2 How to load a package\nWhen you begin a new session in RStudio, i.e. when you open RStudio, only certain core packages are automatically loaded. You can use the library() function to load a package that you has previously been installed. For example, now that we have installed skimr, we need to load it before we can use it:\n\nlibrary(skimr)\n\nNote that quotation marks are not required for the library() function (although they can be included if you really like quotation marks!).\n\n\n\n\n\n\nTASK\n\n\n\nInstall the packages: jmv, skimr and summarytools using Tools > Install packages, or by typing into the console:\ninstall.packages(\"jmv\") install.packages(\"skimr\") install.packages(\"summarytools\")\n\n\n\n\n1.14.7.3 Installing vs loading packages\nPackage installation:\n\nuse the install.packages() function (note the ‘s’) or Tools > Install packages\nthe package name must be surrounded by quotation marks\nonly needs to be done once\n\nPackage loading\n\nuse the library() function\nthe package name does not need to be surrounded by quotation marks\nmust be done for each R session\n\n\n\n\n1.14.8 What is this thing called the tidyverse?\nIf you have done much reading about R, you may have come across the tidyverse:\n\n“The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.” https://www.tidyverse.org/\n\nPackages in the tidyverse have been designed with a goal to make using R more consistent by defining a “grammar” to manipulate data, examine data and draw conclusions from data. While the tidyverse is a common and powerful set of packages, we will not be teaching the tidyverse in this course for two main reasons:\n\nThe data we provide have been saved in a relatively tidy way, and do not need much manipulation for analyses to be conducted. The cognitive load in learning the tidyverse in this course is greater than the benefit that could be gained.\nThere are many resources (online, in print etc) that are based on base R, and do not use the tidyverse. It would be difficult to understand these resources if we taught only tidyverse techniques. In particular, the dataframe$variable syntax is an important concept that should be understood before moving into the tidyverse.\n\nIn saying all of this, I think the tidyverse is an excellent set of packages, which I frequently use. At the completion of this course, you will be well equipped to teach yourself tidyverse using many excellent resources such as: Tidyverse Skills for Data Science and R for Data Science."
  },
  {
    "objectID": "01-intro.html#part-2-obtaining-basic-descriptive-statistics-1",
    "href": "01-intro.html#part-2-obtaining-basic-descriptive-statistics-1",
    "title": "1  Introduction to statistics and presenting data",
    "section": "1.15 Part 2: Obtaining basic descriptive statistics",
    "text": "1.15 Part 2: Obtaining basic descriptive statistics\nIn this exercise, we will analyse data to complete a descriptive table from a research study. The data come from a study in primary biliary cirrhosis, a condition of the liver, from Modeling Survival Data: Extending the Cox Model Therneau and Grambsch (2010). By the end of this exercise, we will have completed the following table.\n\n\n\n\nSummary of 418 participants from the PBC study (Therneau and Grambsch, 2000)\nCharacteristic Summary\n\nAge (years)Mean (SD) or Median [IQR]\n\nSexMalen (%)\n\nFemalen (%)\n\nAST* (U/ml)Mean (SD) or Median [IQR]\n\nSerum bilirubinMean (SD) or Median [IQR]\n\nStageIn (%)\n\nIIn (%)\n\nIIIn (%)\n\nIVn (%)\n\nVital status at study endAlive: no transplantn (%)\n\nAlive: transplantn (%)\n\nDeceasedn (%)\n\n* asparate aminotransferase\n\n\n\n\nThis table is available in Table1.docx, saved on Moodle.\n\n1.15.1 Set up your data\nWe created a project in the previous step. We will now create a folder to store all the data for this course. Storing the data within the project makes life much easier!\nCreate a new folder by clicking the New Folder icon in the Files tab at the bottom-right:\n\n\n\n\n\nCall the new folder data.\nClick on this folder to open it, and then create two new folders: activities and examples.\nDownload the “Data sets: for learning activities” from Moodle, and use Windows Explorer or MacOS Finder to save these data sets in activities. Save the “Data sets: example data from course notes” into the examples folder.\nYour activities folder should look like:\n\n\n\n\n\nClick the two dots next to the up-arrow at the top of the folder contents to move back up the folder structure. Note that you need to click the dots, and not the up-facing green arrow!\n\n\n1.15.2 Reading a data file\nTyping data directly into R is not common; we usually read data that have been previously saved. In this example, we will read an .rds file using the readRDS() function, which has only one input: the location of the file.\n\n\n\n\n\n\nTASK\n\n\n\n1 - Confirm that the pbc.rds file is in the activities sub-folder within the data folder (as per the previous steps).\n2 - Load the skimr package, and use the readRDS() function to read the file into R, assigning it to a data frame called pbc. Because we set up our project, we can locate our data easily by telling R to use the file: \"data/activities/pbc.rds\", which translates as: the file pbc.rds which is located in the activities sub-folder within the data folder.\n\nlibrary(skimr)\n\npbc <- readRDS(\"data/activities/pbc.rds\")\n\n3 - We can now use the summary() function to examine the pbc dataset:\n\nsummary(pbc)\n\n       id             time          status            trt       \n Min.   :  1.0   Min.   :  41   Min.   :0.0000   Min.   :1.000  \n 1st Qu.:105.2   1st Qu.:1093   1st Qu.:0.0000   1st Qu.:1.000  \n Median :209.5   Median :1730   Median :0.0000   Median :1.000  \n Mean   :209.5   Mean   :1918   Mean   :0.8301   Mean   :1.494  \n 3rd Qu.:313.8   3rd Qu.:2614   3rd Qu.:2.0000   3rd Qu.:2.000  \n Max.   :418.0   Max.   :4795   Max.   :2.0000   Max.   :2.000  \n                                                 NA's   :106    \n      age             sex           ascites            hepato      \n Min.   :26.28   Min.   :1.000   Min.   :0.00000   Min.   :0.0000  \n 1st Qu.:42.83   1st Qu.:2.000   1st Qu.:0.00000   1st Qu.:0.0000  \n Median :51.00   Median :2.000   Median :0.00000   Median :1.0000  \n Mean   :50.74   Mean   :1.895   Mean   :0.07692   Mean   :0.5128  \n 3rd Qu.:58.24   3rd Qu.:2.000   3rd Qu.:0.00000   3rd Qu.:1.0000  \n Max.   :78.44   Max.   :2.000   Max.   :1.00000   Max.   :1.0000  \n                                 NA's   :106       NA's   :106     \n    spiders           edema             bili             chol       \n Min.   :0.0000   Min.   :0.0000   Min.   : 0.300   Min.   : 120.0  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.: 0.800   1st Qu.: 249.5  \n Median :0.0000   Median :0.0000   Median : 1.400   Median : 309.5  \n Mean   :0.2885   Mean   :0.1005   Mean   : 3.221   Mean   : 369.5  \n 3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.: 3.400   3rd Qu.: 400.0  \n Max.   :1.0000   Max.   :1.0000   Max.   :28.000   Max.   :1775.0  \n NA's   :106                                        NA's   :134     \n    albumin          copper          alkphos             ast        \n Min.   :1.960   Min.   :  4.00   Min.   :  289.0   Min.   : 26.35  \n 1st Qu.:3.243   1st Qu.: 41.25   1st Qu.:  871.5   1st Qu.: 80.60  \n Median :3.530   Median : 73.00   Median : 1259.0   Median :114.70  \n Mean   :3.497   Mean   : 97.65   Mean   : 1982.7   Mean   :122.56  \n 3rd Qu.:3.770   3rd Qu.:123.00   3rd Qu.: 1980.0   3rd Qu.:151.90  \n Max.   :4.640   Max.   :588.00   Max.   :13862.4   Max.   :457.25  \n                 NA's   :108      NA's   :106       NA's   :106     \n      trig           platelet        protime          stage      \n Min.   : 33.00   Min.   : 62.0   Min.   : 9.00   Min.   :1.000  \n 1st Qu.: 84.25   1st Qu.:188.5   1st Qu.:10.00   1st Qu.:2.000  \n Median :108.00   Median :251.0   Median :10.60   Median :3.000  \n Mean   :124.70   Mean   :257.0   Mean   :10.73   Mean   :3.024  \n 3rd Qu.:151.00   3rd Qu.:318.0   3rd Qu.:11.10   3rd Qu.:4.000  \n Max.   :598.00   Max.   :721.0   Max.   :18.00   Max.   :4.000  \n NA's   :136      NA's   :11      NA's   :2       NA's   :6      \n\n\nAn alternative to the summary() function is the skim() function in the skimr package, which produces summary statistics as well as rudimentary histograms:\n\nskim(pbc)\n\n\n\n\n\n\n\n\nThe summary() and skim() functions are useful to give a quick overview of a dataset: how many variables are included, how variables are coded, which variables contain missing data and a crude histogram showing the distribution of numeric variables.\n\n\n1.15.3 Summarising continuous variables\nOne of the most flexible functions for summarising continuous variables is the descriptives() function from the jmv package. The function is specified as descriptives(data=, vars=) where:\n\ndata specifies the dataframe to be analysed\nvars specifies the variable(s) of interest, with multiple variables combined using the c() function\n\nWe can summarise the three continuous variables in the pbc data: age, AST and serum bilirubin, as shown below.\n\nlibrary(jmv)\n\ndescriptives(data=pbc, vars=c(age, ast, bili))\n\n\n DESCRIPTIVES\n\n Descriptives                                                \n ─────────────────────────────────────────────────────────── \n                         age         ast         bili        \n ─────────────────────────────────────────────────────────── \n   N                          418         312          418   \n   Missing                      0         106            0   \n   Mean                  50.74155    122.5563     3.220813   \n   Median                51.00068    114.7000     1.400000   \n   Standard deviation    10.44721    56.69952     4.407506   \n   Minimum               26.27789    26.35000    0.3000000   \n   Maximum               78.43943    457.2500     28.00000   \n ─────────────────────────────────────────────────────────── \n\n\nBy default, the descriptives function presents the mean, median, standard deviation, minimum and maximum. We can request additional statistics, such as the quartiles (which are called the percentiles, or pc, in the descriptives function):\n\ndescriptives(data=pbc, vars=c(age, ast, bili), pc=TRUE)\n\n\n DESCRIPTIVES\n\n Descriptives                                                \n ─────────────────────────────────────────────────────────── \n                         age         ast         bili        \n ─────────────────────────────────────────────────────────── \n   N                          418         312          418   \n   Missing                      0         106            0   \n   Mean                  50.74155    122.5563     3.220813   \n   Median                51.00068    114.7000     1.400000   \n   Standard deviation    10.44721    56.69952     4.407506   \n   Minimum               26.27789    26.35000    0.3000000   \n   Maximum               78.43943    457.2500     28.00000   \n   25th percentile       42.83231    80.60000    0.8000000   \n   50th percentile       51.00068    114.7000     1.400000   \n   75th percentile       58.24093    151.9000     3.400000   \n ─────────────────────────────────────────────────────────── \n\n\n\n\n1.15.4 Producing a histogram\nWe can use the hist() function to produce a histogram, specifying the dataframe to use and the variable to be plotted as dataframe$variable:\n\nhist(pbc$age)\n\n\n\n\nThe histogram function does a remarkably good job of choosing cutpoints and binwidths, and these rarely need to be changed. However, the labelling of the histogram should be improved by using xlab=\" \" and main=\" \" to assign labels for the x-axis and overall title respectively:\n\nhist(pbc$age, xlab=\"Age (years)\", \n     main=\"Histogram of participant age from pbc study data\")\n\n\n\n\nBy default, the hist() function plots a frequency histogram, with counts on the y-axis. We can tweak the histogram using the following code to plot a histogram of the relative frequencies:\n\nh <- hist(pbc$age, plot=FALSE)\nh$density <- h$counts/sum(h$counts)*100\nplot(h, freq=FALSE, \n     xlab=\"Age (years)\", \n     ylab=\"Relative frequency (%)\",\n     main=\"Histogram of participant age from pbc study data\")\n\n\n\n\n\n\n1.15.5 Producing a boxplot\nThe boxplot function is used to produce boxplots, again specifying the dataframe to use and the variable to be plotted as dataframe$variable. Labels can be applied in the same way as the histogram:\n\nboxplot(pbc$age, xlab=\"Age (years)\", main=\"Boxplot of participant age from pbc study data\")\n\n\n\n\n\n\n1.15.6 Producing a one-way frequency table\nWe have three categorical variables to summarise in Table 1: sex, stage and vital status. These variables are best summarised using one-way frequency tables.\n\nlibrary(summarytools)\n\nfreq(pbc$sex)\n\nFrequencies  \npbc$sex  \nType: Numeric  \n\n              Freq   % Valid   % Valid Cum.   % Total   % Total Cum.\n----------- ------ --------- -------------- --------- --------------\n          1     44     10.53          10.53     10.53          10.53\n          2    374     89.47         100.00     89.47         100.00\n       <NA>      0                               0.00         100.00\n      Total    418    100.00         100.00    100.00         100.00\n\n\n\n1.15.6.1 Defining categorical variables as factors\nYou will notice that the table above, in its current form, is uninterpretable as the 1 and 2 categories are not labelled. In this course, all variables including categorical variables tend to be numerically coded. To define a categorical variable as such in R, we define it as a factor using the factor function:\nfactor(variable=, levels=, labels=)\nWe specify:\n\nlevels: the values the categorical variable can take\nlabels: the labels corresponding to each of the levels (entered in the same order as the levels)\n\nTo define our variable sex as a factor, we use:\n\npbc$sex <- factor(pbc$sex, levels=c(1, 2), labels=c(\"Male\", \"Female\"))\n\nWe can confirm the coding by re-running a frequency table:\n\nfreq(pbc$sex)\n\nFrequencies  \npbc$sex  \nType: Factor  \n\n               Freq   % Valid   % Valid Cum.   % Total   % Total Cum.\n------------ ------ --------- -------------- --------- --------------\n        Male     44     10.53          10.53     10.53          10.53\n      Female    374     89.47         100.00     89.47         100.00\n        <NA>      0                               0.00         100.00\n       Total    418    100.00         100.00    100.00         100.00\n\n\n\nTask: define stage and status (Vital Status) as factors, and produce one-way frequency tables. Refer to the file pbc_info.txt to view the labels for each variable. For example, for Stage:\n\n\npbc$stage <- factor(pbc$stage, levels=c(1, 2, 3, 4), labels=c(\"Stage 1\", \"Stage 2\", \"Stage 3\", \"Stage 4\"))\nfreq(pbc$stage)\n\nFrequencies  \npbc$stage  \nType: Factor  \n\n                Freq   % Valid   % Valid Cum.   % Total   % Total Cum.\n------------- ------ --------- -------------- --------- --------------\n      Stage 1     21      5.10           5.10      5.02           5.02\n      Stage 2     92     22.33          27.43     22.01          27.03\n      Stage 3    155     37.62          65.05     37.08          64.11\n      Stage 4    144     34.95         100.00     34.45          98.56\n         <NA>      6                               1.44         100.00\n        Total    418    100.00         100.00    100.00         100.00\n\n\n\n\n\n1.15.7 Producing a two-way frequency table\nTo produce tables summarising two categorical variables, we can use the contTables() function within the jmv package. The minimal inputs to include are data: the name of the data frame to be analysed, rows: the variable representing the rows of the table, and cols: the name of the columns of the table.\nFor example, to produce a two-way table showing stage of disease by sex using the pbc data frame, we use:\n\ncontTables(data=pbc, rows=sex, cols=stage)\n\n\n CONTINGENCY TABLES\n\n Contingency Tables                                              \n ─────────────────────────────────────────────────────────────── \n   sex       Stage 1    Stage 2    Stage 3    Stage 4    Total   \n ─────────────────────────────────────────────────────────────── \n   Male            3          8         16         17       44   \n   Female         18         84        139        127      368   \n   Total          21         92        155        144      412   \n ─────────────────────────────────────────────────────────────── \n\n\n χ² Tests                               \n ────────────────────────────────────── \n         Value        df    p           \n ────────────────────────────────────── \n   χ²    0.8779873     3    0.8307365   \n   N           412                      \n ────────────────────────────────────── \n\n\n[The bottom part of the output, χ² Tests, can be ignored for now]\nYou may notice in the above that the number of observations is now 412. This is because there are missing observations for either sex or stage: which is it, and how would you determine this?\nFrom the cross-tabulation, you can see the individual frequencies of participants in each of the categories in each cell. For example, there are 3 male participants who have Stage 1 disease. You can also read the totals for each row and column. For example, there are 44 males, and 144 participants have Stage 4 disease.\nYou can also add percentages into your table using pcCol=TRUE to include column percents, and pcRow=TRUE for row percents. For example, to calculate the relative frequencies (i.e. percentages) of sex within each stage, we would request column percents with the option: pcCol=TRUE.\n\ncontTables(data=pbc, rows=sex, cols=stage, pcCol=TRUE)\n\n\n CONTINGENCY TABLES\n\n Contingency Tables                                                                             \n ────────────────────────────────────────────────────────────────────────────────────────────── \n   sex                          Stage 1      Stage 2      Stage 3      Stage 4      Total       \n ────────────────────────────────────────────────────────────────────────────────────────────── \n   Male      Observed                   3            8           16           17           44   \n             % within column     14.28571      8.69565     10.32258     11.80556     10.67961   \n                                                                                                \n   Female    Observed                  18           84          139          127          368   \n             % within column     85.71429     91.30435     89.67742     88.19444     89.32039   \n                                                                                                \n   Total     Observed                  21           92          155          144          412   \n             % within column    100.00000    100.00000    100.00000    100.00000    100.00000   \n ────────────────────────────────────────────────────────────────────────────────────────────── \n\n\n χ² Tests                               \n ────────────────────────────────────── \n         Value        df    p           \n ────────────────────────────────────── \n   χ²    0.8779873     3    0.8307365   \n   N           412                      \n ────────────────────────────────────── \n\n\nWe can see that the 3 male participants with Stage 1 disease represent 14% of those with Stage 1 disease.\n\n\n1.15.8 Saving data in R\nThere are many ways to save data from R, depending on the type of file you want to save. The recommendation for this course is to save your data using the .rds format, using the saveRDS() function, which takes two inputs: saveRDS(object, file). Here, object is the R object to be saved (usually a data frame), and file is the location for the file to be saved (file name and path, including the .rds suffix).\nIt is not necessary to save our PBC data, as we have made only minor changes to the data that can be replicated by rerunning our script. If you had made major changes and wanted to save your data, you could use:\nsaveRDS(pbc, file=\"pbc_revised.rds\")\n\n\n1.15.9 Copying output from R\nIt is important to note that saving your data or your script in R will not save your output. The easiest way to retain the output of your analyses is to copy the output from the Console into a word processor package (e.g. Microsoft Word) before closing R.\nUnfortunately, by default, R is not ideal for creating publication quality tables. There are many packages that will help in this process, such as R Markdown, bookdown1, huxtable, gt and gtsummary, but their use is beyond the scope of this course. R Markdown for Scientists provides an excellent introduction to R Markdown.\n\n\n\n\n\n\nTASK\n\n\n\nComplete Table 1 using the output generated in this exercise. You should decide on whether to present continuous variables by their means or medians, and present the most appropriate measure of spread. Include footnotes to indicate if any variables contain missing observations."
  },
  {
    "objectID": "01-intro.html#part-3-creating-other-types-of-graphs-1",
    "href": "01-intro.html#part-3-creating-other-types-of-graphs-1",
    "title": "1  Introduction to statistics and presenting data",
    "section": "1.16 Part 3: Creating other types of graphs",
    "text": "1.16 Part 3: Creating other types of graphs\nThe plot() function, also known as base graphics, is the default method of plotting data in R that can produce publication-quality graphics with minimal coding. There are alternative packages for plotting, with ggplot2 being one of the most well known. We will present instructions for base graphics in this course, but excellent documentation for ggplot2 can be found at the ggplot2: Elegant Graphics for Data Analysis website, written by the package authors.\n\n1.16.1 Bar graphs\nThe simplest way to use the plot() function is by specifying an object to be plotted. As with the hist() function, to plot a single variable from a data frame, we must define it using: dataframe$variable.\nHere we will create the bar chart shown in Figure 1.3 of the statistics notes using the pbc.rds dataset. The x-axis of this graph will be the stage of disease, and the y-axis will show the number of participants in each category.\n\nplot(pbc$stage, \n     main=\"Bar graph of stage of disease from PBC study\", \n     ylab=\"Number of participants\")\n\n\n\n\nNote that stage is a categorical variable, that has been defined as a factor (in Section 1.15.6.1). You must define categorical data as factors to plot them in a bar graph.\n\n1.16.1.1 Clustered bar graph\nTo create a clustered bar chart as shown in Figure 1.4 of the statistics notes, we need to do a bit of manipulation. We first need to tabulate the data using the table() function. We want to plot stage of disease broken down by sex, so we specify sex as the first variable, and stage as the second variable for the table() command.\n\ncounts <- table(pbc$sex, pbc$stage)\ncounts\n\n        \n         Stage 1 Stage 2 Stage 3 Stage 4\n  Male         3       8      16      17\n  Female      18      84     139     127\n\n\nAfter tabulating the data, we use the barplot() function to plot the summarised data. We specify the main title using main=\" \", specify that the stages be plotted separately by sex (beside=TRUE), specify the legend be defined by sex, and position the legend in the top-left of the graph:\n\nbarplot(counts, main=\"Bar graph of stage of disease by sex from PBC study\",\n        beside=TRUE, legend = rownames(counts), args.legend = list(x = \"topleft\"))\n\n\n\n\n\n\n1.16.1.2 Stacked bar graph\nA stacked bar graph can be constructed as for the clustered bar graph, but we specify beside=FALSE:\n\nbarplot(counts, main=\"Bar graph of stage of disease by sex from PBC study\",\n        beside=FALSE, legend = rownames(counts), args.legend = list(x = \"topleft\"))\n\n\n\n\n\n\n1.16.1.3 Stacked bar graph of relative frequencies\nTo plot relative frequencies, we need to transform our table of frequencies (counts) into proportions, by using the prop.table() function. The prop.table() function takes two arguments: a table of counts, and margin, which defines whether we want proportions calculated by row (margin=1) or column (margin=2).\nWe want to calculate the relative frequency of sex within each stage category. From our counts table above, this equates to calculating column proportions, so we specify margin=2. We also multiply the resulting table by 100 to obtain percentages (rather than proportions):\n\npercent <- prop.table(counts, margin=2)*100\npercent\n\n        \n           Stage 1   Stage 2   Stage 3   Stage 4\n  Male   14.285714  8.695652 10.322581 11.805556\n  Female 85.714286 91.304348 89.677419 88.194444\n\n\nAfter calculating the percentages, we use barplot() again, similar to the stacked bar graph:\n\nbarplot(percent, \n        main=\"Relative frequency of sex within stage of disease from PBC study\",\n        legend = rownames(counts), beside=FALSE, args.legend = list(x = \"topright\"))\n\n\n\n\n\n\n\n1.16.2 Creating line graphs\nTo demonstrate the graphing of aggregate data , we use the data on new cases and deaths from prostate cancer in males in NSW. This data has been entered as Example_1.2.rds.\n\ncancer <- readRDS(\"data/examples/Example_1.2.rds\")\nsummary(cancer)\n\n      year          ncases        ndeaths           rcases         rdeaths     \n Min.   :1987   Min.   :1567   Min.   : 645.0   Min.   : 81.8   Min.   :31.10  \n 1st Qu.:1992   1st Qu.:2804   1st Qu.: 788.2   1st Qu.:121.9   1st Qu.:34.67  \n Median :1996   Median :3790   Median : 868.0   Median :131.3   Median :36.55  \n Mean   :1996   Mean   :3719   Mean   : 855.0   Mean   :135.4   Mean   :37.09  \n 3rd Qu.:2001   3rd Qu.:4403   3rd Qu.: 921.0   3rd Qu.:164.2   3rd Qu.:40.38  \n Max.   :2006   Max.   :6158   Max.   :1044.0   Max.   :186.9   Max.   :43.80  \n\n\nWe begin by plotting cancer cases (as the y variable) against year (the x variable).\n\nplot(x=cancer$year, y=cancer$rcases)\n\n\n\n\nLet’s define the plot to be joined by lines (type=\"l\"), in the colour red (col=\"red\"), providing meaningful labels for the x-axis and y-axis, and changing the scale of the y-axis to be between 0 and 200 (ylim=c(0,200)):\n\nplot(x=cancer$year, y=cancer$rcases, \n     type=\"l\", col = \"red\", \n     xlab = \"Year\", \n     ylab = \"Age-standardised rate (per 100,000)\", ylim=c(0,200))\n\n\n\n\nWe can now add a second line to the plot using the lines() function, specifying a dashed line (lty=2), and add a legend to the plot:\n\nplot(x=cancer$year, y=cancer$rcases, type=\"l\", col = \"red\", \n     xlab = \"Year\", ylab = \"Age-standardised rate (per 100,000)\", \n     ylim=c(0,200))\n\nlines(cancer$year, cancer$rdeaths, col = \"blue\", type = \"l\", lty = 2)\n\nlegend(\"topleft\", legend=c(\"Incidence\", \"Deaths\"), \n       col=c(\"red\", \"blue\"), lty = 1:2)\n\n\n\n\nNote: coding for graphs is not always straightforward. Two excellent resources for creating graphs in R are: R Graphics Cookbook and The R Graph Gallery."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Acock, Alan C. 2010. A Gentle Introduction to\nStata. 3rd ed. College Station, Tex:\nStata Press.\n\n\nAltman, Douglas G. 1990. Practical Statistics for\nMedical Research. 1st ed. Boca Raton,\nFla: Chapman and Hall/CRC.\n\n\nArmitage, Peter, Geoffrey Berry, and J. N. S. Matthews. 2013.\nStatistical Methods in Medical\nResearch. 4th ed. Wiley-Blackwell.\n\n\nAssel, Melissa, Daniel Sjoberg, Andrew Elders, Xuemei Wang, Dezheng Huo,\nAlbert Botchway, Kristin Delfino, et al. 2019. “Guidelines for\nReporting of Statistics for Clinical Research in Urology.”\nBJU International 123 (3): 401–10. https://doi.org/10.1111/bju.14640.\n\n\nAustralian Bureau of Statistics. 2021. “Causes of\nDeath, Australia, 2020.”\nhttps://www.abs.gov.au/statistics/health/causes-death/causes-death-australia/latest-release.\n\n\nAustralian Institute of Health and Welfare. 2021. “Australia’s\nMothers and Babies.”\nhttps://www.aihw.gov.au/reports/mothers-babies/australias-mothers-babies.\n\n\nBland, Martin. 2015. An Introduction to Medical\nStatistics. 4th ed. Oxford, New York:\nOxford University Press.\n\n\nBoers, Maarten. 2018. “Graphics and Statistics for Cardiology:\nDesigning Effective Tables for Presentation and Publication.”\nHeart 104 (3): 192–200. https://doi.org/10.1136/heartjnl-2017-311581.\n\n\nCole, T. J. 2015. “Too Many Digits: The Presentation of Numerical\nData.” Archives of Disease in Childhood 100 (7): 608–9.\nhttps://doi.org/10.1136/archdischild-2014-307149.\n\n\nKirkwood, Betty, and Jonathan Sterne. 2001. Essentials of\nMedical Statistics. 2nd ed. Malden, Mass:\nWiley-Blackwell.\n\n\nTherneau, Terry M., and Patricia M. Grambsch. 2010. Modeling\nSurvival Data: Extending the Cox\nModel. New York Berlin Heidelberg:\nSpringer.\n\n\nVickers, Andrew J., Melissa J. Assel, Daniel D. Sjoberg, Rui Qin, Zhiguo\nZhao, Tatsuki Koyama, Albert Botchway, et al. 2020. “Guidelines\nfor Reporting of Figures and\nTables for Clinical Research in\nUrology.” European Urology, May. https://doi.org/10.1016/j.eururo.2020.04.048."
  }
]