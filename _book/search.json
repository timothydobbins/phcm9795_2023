[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PHCM9795: Foundations of Biostatistics",
    "section": "",
    "text": "Course introduction\nWelcome to PHCM9795 Foundations of Biostatistics.\nThis introductory course in biostatistics aims to provide students with core biostatistical skills to analyse and present quantitative data from different study types. These are essential skills required in your degree and throughout your career.\nWe hope you enjoy the course and will value your feedback and comment throughout the course."
  },
  {
    "objectID": "index.html#course-information",
    "href": "index.html#course-information",
    "title": "PHCM9795: Foundations of Biostatistics",
    "section": "Course information",
    "text": "Course information\nBiostatistics is a foundational discipline needed for the analysis and interpretation of quantitative information and its application to population health policy and practice.\nThis course is central to becoming a population health practitioner as the concepts and techniques developed in the course are fundamental to your studies and practice in population health. In this course you will develop an understanding of, and skills in, the core concepts of biostatistics that are necessary for analysis and interpretation of population health data and health literature.\nIn designing this course, we provide a learning sequence that will allow you to obtain the required graduate capabilities identified for your program. This course is taught with an emphasis on formulating a hypothesis and quantifying the evidence in relation to a specific research question. You will have the opportunity to analyse data from different study types commonly seen in population health research.\nThe course will allow those of you who have covered some of this material in your undergraduate and other professional education to consolidate your knowledge and skills. Students exposed to biostatistics for the first time may find the course challenging at times. Based on student feedback, the key to success in this course is to devote time to it every week. We recommend that you spend an average of 10-15 hours per week on the course, including the time spent reading the course notes and readings, listening to lectures, and working through learning activities and completing your assessments. Please use the resources provided to assist you, including online support."
  },
  {
    "objectID": "index.html#units-of-credit",
    "href": "index.html#units-of-credit",
    "title": "PHCM9795: Foundations of Biostatistics",
    "section": "Units of credit",
    "text": "Units of credit\nThis course is a core course of the Master of Public Health, Master of Global Health and Master of Infectious Diseases Intelligence programs and associated dual degrees, comprising 6 units of credit towards the total required for completion of the study program. A value of 6 UOC requires a minimum of 150 hours work for the average student across the term."
  },
  {
    "objectID": "index.html#course-aim",
    "href": "index.html#course-aim",
    "title": "PHCM9795: Foundations of Biostatistics",
    "section": "Course aim",
    "text": "Course aim\nThis course aims to provide students with the core biostatistical skills to apply appropriate statistical techniques to analyse and present population health data."
  },
  {
    "objectID": "index.html#learning-outcomes",
    "href": "index.html#learning-outcomes",
    "title": "PHCM9795: Foundations of Biostatistics",
    "section": "Learning outcomes",
    "text": "Learning outcomes\nOn successful completion of this course, you will be able to:\n\nSummarise and visualise data using statistical software.\nDemonstrate an understanding of statistical inference by interpreting p-values and confidence intervals.\nApply appropriate statistical tests for different types of variables given a research question, and interpret computer output of these tests appropriately.\nDetermine the appropriate sample size when planning a research study.\nPresent and interpret statistical findings appropriate for a population health audience."
  },
  {
    "objectID": "03-precision.html",
    "href": "03-precision.html",
    "title": "1  Precision, standard errors and confidence intervals",
    "section": "",
    "text": "Stata notes"
  },
  {
    "objectID": "03-precision.html#learning-objectives",
    "href": "03-precision.html#learning-objectives",
    "title": "1  Precision, standard errors and confidence intervals",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of this module you will be able to:\n\nExplain the purpose of sampling, different sampling methods and their implications for data analysis;\nDistinguish between standard deviation of a sample and standard error of a mean;\nRecognise the importance of the central limit theorem;\nCalculate the standard error of a mean;\nCalculate and interpret confidence intervals for a mean;\nBe familiar with the t-distribution and when to use it."
  },
  {
    "objectID": "03-precision.html#readings",
    "href": "03-precision.html#readings",
    "title": "1  Precision, standard errors and confidence intervals",
    "section": "Readings",
    "text": "Readings\nKirkwood and Sterne (2001); Chapters 4 and 6. [UNSW Library Link]\nBland (2015); Sections 3.3 and 3.4, 8.1 to 8.3. [UNSW Library Link]"
  },
  {
    "objectID": "03-precision.html#introduction",
    "href": "03-precision.html#introduction",
    "title": "1  Precision, standard errors and confidence intervals",
    "section": "1.1 Introduction",
    "text": "1.1 Introduction\nTo describe the characteristics of a population we can gather data about the entire population (as is undertaken in a national census) or we can gather data from a sample of the population. When undertaking a research study, taking a sample from a population is far more cost-effective and less time consuming than collecting information from the entire population. When a sample of a population is selected, summary statistics that describe the sample are used to make inferences about the total population from which the sample was drawn. These are referred to as inferential statistics.\nHowever, for the inferences about the population to be valid, a random sample of the population must be obtained. The goal of using random sampling methods is to obtain a sample that is representative of the target population. In other words, apart from random error, the information derived from the sample is expected to be much the same as the information collected from a complete population census as long as the sample is large enough."
  },
  {
    "objectID": "03-precision.html#sampling-methods",
    "href": "03-precision.html#sampling-methods",
    "title": "1  Precision, standard errors and confidence intervals",
    "section": "1.2 Sampling methods",
    "text": "1.2 Sampling methods\nMethods have been designed to select participants from a population such that each person in the target population has an equal probability of being chosen. Methods that use this approach are called random sampling methods. Examples include simple random sampling and stratified random sampling.\nIn simple random sampling, every person in the population from which the sample is drawn has the same random chance of being selected into the sample. To implement this method, every person in the population is allocated an ID number and then a random sample of the ID numbers is selected. Software packages can be used to generate a list of random numbers to select the random sample.\nIn stratified sampling, the population is divided into distinct non-overlapping subgroups (strata) according to an important characteristic (e.g. age or sex) and then a random sample is selected from each of the strata. This method is used to ensure that sufficient numbers of people are sampled from each stratum and therefore each subgroup of interest is adequately represented in the sample.\nThe purpose of using random sampling is to minimise selection bias to ensure that the sample enrolled in a study is representative of the population being studied. This is important because the summary statistics that are obtained can then be regarded as valid in that they can be applied (generalised) back to the population.\nA non-representative sample might occur when random sampling is used, simply by chance. However, non-random sampling methods, such as using a study population that does not represent the whole population, will often result in a non-representative sample being selected so that the summary statistics from the sample cannot be generalised back to the population from which the participants were drawn. The effects of non-random error are much more serious than the effects of random error. Concepts such as non-random error (i.e. systematic bias), selection bias, validity and generalisability are discussed in more detail in PHCM9796: Foundations of Epidemiology."
  },
  {
    "objectID": "03-precision.html#standard-error-and-precision",
    "href": "03-precision.html#standard-error-and-precision",
    "title": "1  Precision, standard errors and confidence intervals",
    "section": "1.3 Standard error and precision",
    "text": "1.3 Standard error and precision\nModule 1 introduced the mean, variance and standard deviation as measures of central tendency and spread for continuous measurements from a sample or a population. As described in Module 1, we rarely have data on the entire population but we can infer information about the population (e.g. the mean weight of people in the population) based on a sample. However, a sample taken from a population is usually a small proportion of the total population. If the sample is very small, we would not expect our estimate of the population mean value to be precise. If the sample is very large, we would expect a more precise estimate of the population mean, i.e. the estimated mean value would be much closer to the true mean value in the population.\n\n1.3.1 The standard error of the mean\nA point estimate is a single best guess of the true value in the population. Instead of trying to guess the true value, it may be preferable to give a range of values in which we think the true value lies. For example, suppose we want to estimate the average weight of a population, and found a sample mean of 65 kg. Rather than saying we believe the true mean to be 65 kg, we could say we believe it is somewhere between, say, 58 kg and 72 kg.\nOften in papers, one will see something like “the mean is 70.24 \\(\\pm\\) 1.78 kg”. The value 1.78 is the standard error of the mean (sometimes shortened to S.E.M. or S.E.). The standard error of the mean measures the extent to which we expect the means from different samples to vary because of chance error in the sampling process. The standard error is a measure of precision of the point estimate. This statistic is directly proportional to the standard deviation of the variable, and inversely proportional to the size of the sample. The standard error of the mean for a continuously distributed measurement for which the SD is an accurate measure of spread is computed as follows:\n\\[ \\text{SE}(\\bar{x}) = \\frac{\\text{SD}}{\\sqrt{n}} \\] For our sample of weight data from 30 patients in Module 1:\n\\[ \\text{SE}(\\bar{x}) = \\frac{\\text{5.04}}{\\sqrt{30}} = 0.92 \\] Because the calculation uses the sample size (n) (i.e. the number of study participants) in the denominator, the SE will become smaller when the sample size becomes larger. A smaller SE indicates that the estimated mean value is more precise.\nThe standard error is an important statistic that is related to sampling variation. When a random sample of a population is selected, it is likely to differ in some characteristic compared with another random sample selected from the same population. Also, when a sample of a population is taken, the true population mean is an unknown value.\nJust as the standard deviation measures the spread of the data around the population mean, the standard error of the mean measures the spread of the sample means. Note that we do not have different samples, only one. It is a theoretical concept which enables us to conduct various other statistical analyses."
  },
  {
    "objectID": "03-precision.html#central-limit-theorem",
    "href": "03-precision.html#central-limit-theorem",
    "title": "1  Precision, standard errors and confidence intervals",
    "section": "1.4 Central limit theorem",
    "text": "1.4 Central limit theorem\nEven though we now have an estimate of the mean and its standard error, we might like to know what the mean from a different random sample of the same size might be. To do this, we need to know how sample means are distributed. In determining the form of the probability distribution of the sample mean (\\(\\bar{x}\\)), we consider two cases:\n\n1.4.1 When the population distribution is unknown:\nThe central limit theorem for this situation states:\n\nIn selecting random samples of size \\(n\\) from a population with mean \\(\\mu\\) and standard deviation \\(\\sigma\\), the sampling distribution of the sample mean \\(\\bar{x}\\) approaches a normal distribution with mean \\(\\mu\\) and standard deviation \\(\\tfrac{\\sigma}{\\sqrt{n}}\\) as the sample size becomes large.\n\nThe sample size n = 30 and above is a rule of thumb for the central limit theorem to be used. However, larger sample sizes may be needed if the distribution is highly skewed.\n\n\n1.4.2 When the population is assumed to be normal:\nIn this case the sampling distribution of \\(\\bar{x}\\) is normal for any sample size."
  },
  {
    "objectID": "03-precision.html#confidence-interval-of-the-mean",
    "href": "03-precision.html#confidence-interval-of-the-mean",
    "title": "1  Precision, standard errors and confidence intervals",
    "section": "1.5 95% confidence interval of the mean",
    "text": "1.5 95% confidence interval of the mean\nIn Module 2, we showed that the characteristics of a Standard Normal Distribution are that 95% of the data lie within 1.96 standard deviations from the mean (Figure 2.2). Because the central limit theorem states that the sampling distribution of the mean is approximately Normal in large enough samples, we expect that 95% of the mean values would fall within 1.96 × SE units above and below the measured mean population value.\nFor example, if we repeated the study on weight 100 times using 100 different random samples from the population and calculated the mean weight for each of the 100 samples, approximately 95% of the values for the mean weight calculated for each of the 100 samples would fall within 1.96 × SE of the population mean weight.\nThis interpretation of the SE is translated into the concept of precision as a 95% confidence interval (CI). A 95% CI is a range of values within which we have 95% confidence that the true population mean lies. If an experiment was conducted a very large number of times, and a 95%CI was calculated for each experiment, 95% of the confidence intervals would contain the true population mean.\nThe calculation of the 95% CI for a mean is as follows:\n\\[  \\bar{x} \\pm 1.96 \\times \\text{SE}( \\bar{x} ) \\] This is the generic formula for calculating 95% CI for any summary statistic. In general, the mean value can be replaced by the point estimate of a rate or a proportion and the same formula applies for computing 95% CIs, i.e.\n\\[ 95\\% \\text{ CI} = \\text{point estimate} \\pm 1.96 \\times \\text{SE}(\\text{point estimate)} \\]\nThe main difference in the methods used to calculate the 95% CI for different point estimates is the way the SE is calculated. The methods for calculating 95% CI around proportions and other ratio measures will be discussed in Module 6.\nThe use of 1.96 as a general critical value to compute the 95% CI is determined by sampling theory. For the confidence interval of the mean, the critical value (1.96) is based on normal distribution (true when the population SD is known). However, in practice, Stata and other statistical packages will provide slightly different confidence intervals because they use a critical value obtained from the t-distribution. The t-distribution approaches a normal distribution when the sample size approaches infinity, and is close to a normal distribution when the sample size is ≥30.The critical values obtained from the t-distribution are always larger than the corresponding critical value from the normal distribution. The difference gets smaller as the sample size becomes larger. For example, when the sample size n=10, the critical value from the t-distribution is 2.26 (rather than 1.96); when n= 30, the value is 2.05; when n=100, the value is 1.98; and when n=1000, the critical value is 1.96.\nThe critical value multiplied by SE (for normal distribution, 1.96 × SE) is called the maximum likely error for 95% confidence.\n\n1.5.1 Worked Example 3.1: 95% CI of a mean\nFor our sample of weights data with standard error of 0.92:\n\\[\n\\begin{aligned}\n\\ 95\\% \\text{ CI}(\\bar{x}) &=  \\bar{x} \\pm 1.96 \\times \\text{SE}(\\bar{x}) \\\\\n&= 70.0 \\pm 1.96 \\times 0.92 \\\\\n&= 68.2 \\text{ to } 71.8 \\text{kg}\n\\end{aligned}\n\\] We interpret this confidence interval as: we are 95% confident that the true mean of the population from which our sample was drawn lies between 68.2 kg and 71.8 kg.\nThis calculation takes into account both the sample mean of 70.0 kg and the sampling error that has arisen by chance due to the sample size of 30 people.\nFor a 95% CI to be reported around a mean value, the data values need to be approximately normally distributed, as discussed in Module 2.\n\n\n1.5.2 The t-distribution and when should I use it?\nThe population standard deviation (\\(\\sigma\\)) is required for calculation of the standard error. Usually, \\(\\sigma\\) is not known and the sample standard deviation (\\(s\\)) is used to estimate it. It is known, however, that the sample standard deviation of a normally distributed variable underestimates the true value of \\(\\sigma\\), particularly when the sample size is small.\nSomeone by the pseudonym of Student came up with the Student’s t distribution with (\\(n-1\\)) degrees of freedom to account for this underestimation. It looks very much like the standardised normal distribution, only that it has fatter tails (Figure 1.1). As the degrees of freedom increase (i.e. as \\(n\\) increases), the t-distribution gradually approaches the standard normal distribution. With a sufficiently large sample size, the Student’s t-distribution closely approximates the standardised normal distribution.\n\n\n\n\n\nFigure 1.1: The normal (Z) and the student’s t-distribution with 2, 5 and 30 degrees of freedom\n\n\n\n\nIf a variable \\(X\\) is normally distributed and the population standard deviation \\(\\sigma\\) is known, using the normal distribution is appropriate. However, if \\(\\sigma\\) is not known then one should use the student t-distribution with (\\(n – 1\\)) degrees of freedom.\n\n\n1.5.3 Worked Example 3.2\nThe publication of a study using a sample of 30 patients reported a sample mean of 70 kg and a sample standard deviation of 6 kg. Find the 95% confidence interval estimate for the mean weight from this sample.\nIn Stata we use the cii means command to compute the 95% confidence interval given the sample mean, sample standard deviation and the sample size (i.e. without using individual data from a dataset) (Section 1.7):\n\n. cii means 30 70 6\n\n    Variable |        Obs        Mean    Std. Err.       [95% Conf. Interval]\n-------------+---------------------------------------------------------------\n             |         30          70    1.095445        67.75956    72.24044\n\nIn R we use the ci_mean function provided in Section 1.9:\n\n\n\n\nci_mean(n=30, mean=70, sd=6, width=0.95)\n\n[1] \"95% CI: 67.760 to 72.240\"\n\n\nBoth commands use the t-distribution, and the output can be interpreted as: we are 95% confident that the true mean weight of the population from which the sample was drawn lies between 67.8 kg and 72.2 kg."
  },
  {
    "objectID": "03-precision.html#sec-cimean-stata-ind",
    "href": "03-precision.html#sec-cimean-stata-ind",
    "title": "1  Precision, standard errors and confidence intervals",
    "section": "1.6 Calculating a 95% confidence interval of a mean: Individual data",
    "text": "1.6 Calculating a 95% confidence interval of a mean: Individual data\nTo demonstrate the computation of the 95% confidence interval of a mean we have used data from Example_1.3.dta. To calculate the 95% confidence interval, go to Statistics > Summaries, tables, and tests > Summary and descriptive statistics > Confidence intervals. In the ci dialog box, select weight as the Variable.\n\n\n\n\n\nFigure 1.2: Calculating a confidence interval from individual data\n\n\n\n\nClick OK or Submit to obtain Output 3.1.\n[Command: ci means weight]"
  },
  {
    "objectID": "03-precision.html#sec-cimean-stata-summ",
    "href": "03-precision.html#sec-cimean-stata-summ",
    "title": "1  Precision, standard errors and confidence intervals",
    "section": "1.7 Calculating a 95% confidence interval of a mean: Summarised data",
    "text": "1.7 Calculating a 95% confidence interval of a mean: Summarised data\nFor Worked Example 3.2 where we are given the sample mean, sample standard deviation and sample size, we use the cii means command. To calculate the 95% CI, go to Statistics > Summaries, tables, and tests > Summary and descriptive statistics > Normal mean CI calculator. In the cii dialog box, check that the Normal mean button is selected, and enter 30 as the Sample size, 70 as the Sample mean, 6 as the Sample standard deviation and check that 95 in entered as the Confidence level.\n\n\n\n\n\nFigure 1.3: Calculating a confidence interval from summarised data\n\n\n\n\nClick OK or Submit to obtain the following output:\n\nStata Output 3.2: 95%CI for a given sample mean, sample standard deviation and sample size\n\n. cii means 30 70 6\n\n    Variable |        Obs        Mean    Std. Err.       [95% Conf. Interval]\n-------------+---------------------------------------------------------------\n             |         30          70    1.095445        67.75956    72.24044"
  },
  {
    "objectID": "03-precision.html#sec-cimean-r-ind",
    "href": "03-precision.html#sec-cimean-r-ind",
    "title": "1  Precision, standard errors and confidence intervals",
    "section": "1.8 Calculating a 95% confidence interval of a mean: individual data",
    "text": "1.8 Calculating a 95% confidence interval of a mean: individual data\nTo demonstrate the computation of the 95% confidence interval of a mean we have used data from Example_1.3.rds which contains the weights of 30 students:\n\nstudents <- readRDS(\"data/examples/Example_1.3.rds\")\n\nWe can examine the data set using the summary command: ::: {.cell}\nsummary(students)\n\n     weight         gender  \n Min.   :60.00   Male  :16  \n 1st Qu.:67.50   Female:14  \n Median :70.00              \n Mean   :70.00              \n 3rd Qu.:74.38              \n Max.   :80.00              \n\n:::\nThe mean and its 95% confidence interval can be obtained many ways in R. We will use the t.test() function installed in R to calculate the confidence interval:\n\nt.test(students$weight)\n\n\n    One Sample t-test\n\ndata:  students$weight\nt = 76.029, df = 29, p-value < 2.2e-16\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 68.11694 71.88306\nsample estimates:\nmean of x \n       70 \n\n\nThe output of the t.test() function gives us the sample mean (70.0 kg) as well as the 95% confidence interval around the mean: 68.1 to 71.9 kg.\nNote: the descriptives() function within the jmv package also calculates a 95% confidence interval around the mean. It is recommended not to use this function as it currently (as of June 2022) uses a z value to calculate the confidence interval, rather than a t value."
  },
  {
    "objectID": "03-precision.html#sec-cimean-r-summ",
    "href": "03-precision.html#sec-cimean-r-summ",
    "title": "1  Precision, standard errors and confidence intervals",
    "section": "1.9 Calculating a 95% confidence interval of a mean: summarised data",
    "text": "1.9 Calculating a 95% confidence interval of a mean: summarised data\nFor Worked Example 3.2 where we are given the sample mean, sample standard deviation and sample size. R does not have a built-in function to calculate a confidence interval from summarised data, but we can write our own.\nNote: writing your own functions is beyond the scope of this course. You should copy and paste the code provided to do this.\n\n### Copy this section\nci_mean <- function(n, mean, sd, width=0.95, digits=3){\n  lcl <- mean - qt(p=(1 - (1-width)/2), df=n-1) * sd/sqrt(n)\n  ucl <- mean + qt(p=(1 - (1-width)/2), df=n-1) * sd/sqrt(n)\n  \n  print(paste0(width*100, \"%\", \" CI: \", format(round(lcl, digits=digits), nsmall = digits),\n               \" to \", format(round(ucl, digits=digits), nsmall = digits) ))\n\n}\n### End of copy\n\nci_mean(n=30, mean=70, sd=6, width=0.95)\n\n[1] \"95% CI: 67.760 to 72.240\"\n\nci_mean(n=30, mean=70, sd=6, width=0.99)\n\n[1] \"99% CI: 66.981 to 73.019\""
  },
  {
    "objectID": "04-hypothesis-testing.html",
    "href": "04-hypothesis-testing.html",
    "title": "2  Hypothesis testing",
    "section": "",
    "text": "Stata notes"
  },
  {
    "objectID": "04-hypothesis-testing.html#learning-objectives",
    "href": "04-hypothesis-testing.html#learning-objectives",
    "title": "2  Hypothesis testing",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of this module you will be able to:\n\nFormulate a research question as a hypothesis;\nUnderstand the concepts of a hypothesis test;\nConsider the difference between statistical significance and clinical importance;\nUse 95% confidence intervals to conduct an informal hypothesis test;\nPerform and interpret a one-sample t-test;\nExplain the concept of one and two tailed statistical tests."
  },
  {
    "objectID": "04-hypothesis-testing.html#readings",
    "href": "04-hypothesis-testing.html#readings",
    "title": "2  Hypothesis testing",
    "section": "Readings",
    "text": "Readings\nKirkwood and Sterne (2001); Chapter 8. [UNSW Library Link]\nBland (2015); Sections 9.1 to 9.7; Sections 10.1 and 10.2. [UNSW Library Link]\nAcock (2010); Section 7.4."
  },
  {
    "objectID": "04-hypothesis-testing.html#introduction",
    "href": "04-hypothesis-testing.html#introduction",
    "title": "2  Hypothesis testing",
    "section": "2.1 Introduction",
    "text": "2.1 Introduction\nIn earlier modules, we examined sampling and how summary statistics can be used to make inferences about a population from which a sample is drawn. In this module, we introduce hypothesis testing as the basis of the statistical tests that are important for reporting results from research and surveillance studies, and that you will be learning in the remainder of this course.\nWe use hypothesis testing to answer questions such as whether two groups have different health outcomes or whether there is an association between a treatment and a health outcome. For example, we may want to know:\n\nwhether a safety program has been effective in reducing injuries in a factory, i.e. whether the frequency of injuries in the group who attended a safety program is lower than in the group who did not receive the safety program;\nwhether a new drug is more effective in reducing blood pressure than a conventional drug, i.e. whether the mean blood pressure in the group receiving the new drug is lower than the mean blood pressure in the group receiving the conventional medication;\nwhether an environmental exposure increases the risk of a disease, i.e. whether the frequency of disease is higher in the group who have been exposed to an environmental factor than in the non-exposed group.\n\nWe may also want to know something about a single group. For example, whether the mean blood pressure of a sample is the same as the general population.\nThese questions can be answered by setting up a null hypothesis and an alternative hypothesis, and performing a hypothesis test (also known as a significance test)."
  },
  {
    "objectID": "04-hypothesis-testing.html#hypothesis-testing",
    "href": "04-hypothesis-testing.html#hypothesis-testing",
    "title": "2  Hypothesis testing",
    "section": "2.2 Hypothesis testing",
    "text": "2.2 Hypothesis testing\nHypothesis testing is a statistical technique that is used to quantify the evidence against a null hypothesis. A null hypothesis (H0) is a statement that there is no difference in a summary statistic between groups. For example, a null hypothesis may be stated as follows:\nH0 = there is no difference in mean systolic blood pressure between a group taking a conventional drug and a group taking a newly developed drug\nWe also have an alternative hypothesis that is opposite or contrasting to the null hypothesis. In our example above, the alternative hypothesis above we be that there is a difference between groups. The alternative hypothesis is usually of most interest to the researcher but in practice, formal statistical tests are used to test the null hypothesis (not the alternative hypothesis). The hypotheses are always in reference to the population from which the sample is drawn, not the sample itself.\nAfter setting up our null and alternative hypotheses, we use the data to generate a test statistic. The particular test statistic differs depending on the type of data being analyses (e.g. continuous or categorical), the study design (e.g. paired or independent) and the question being asked.\nThe test statistic is then compared to a known distribution to calculate the probability of observing a test statistic which is as large or larger than the observed test statistic, if the null hypothesis was true. The probability is known as the P-value. Informally, the P-value can be interpreted as the probability of observing data like ours, or more extreme, if the null hypothesis was true.\nIf the P-value is small, it is unlikely that we would observe data like ours or more extreme if the null hypothesis was true. In other words, our data are not consistent with the null hypothesis, and we conclude that we have evidence against the null hypothesis. If the P-value is not small, the probability of observing data like ours or more extreme is not unlikely. We therefore have little or no evidence against the null hypothesis. In hypothesis testing, the null hypothesis cannot be proven or accepted; we can only find evidence to refute the null hypothesis.\nTo summarise:\n\na small P-value gives us evidence against the null hypothesis;\na P-value that is not small provides little or no evidence against null hypothesis;\nthe smaller the P-value, the stronger the evidence against the null hypothesis.\n\nHistorically, a value of 0.05 has been used as a cut-point for finding evidence against the null hypothesis. A P-value less than 0.05 would be interpreted as “statistically significant”, and would allow us to “reject the null hypothesis”. A P-value greater than 0.05 would be interpreted as “not significant”, and we would “fail to reject the null hypothesis”. This arbitrary dichotomy is overly simplistic, and a more nuanced view is now recommended. Possible interpretations for P-values are given in Table 2.1.\n\n\n\n\nTable 2.1:  Interpretation of P-values \n\nSize of P valueStrength of evidence\n\n<0.001Very strong evidence\n\n0.001 to <0.01Strong evidence\n\n0.01 to <0.05Evidence\n\n0.05 to <0.1Weak evidence\n\n≥0.1Little or no evidence\n\n\n\n\n\nP-values are usually generated using statistical software although other methods such as statistical tables or Excel functions can be used to generate test statistics and determine the P-value. In traditional statistics, the probability level was described as a lower-case p but in many journals today, probability is commonly described by upper case P. Both have the same meaning."
  },
  {
    "objectID": "04-hypothesis-testing.html#effect-size",
    "href": "04-hypothesis-testing.html#effect-size",
    "title": "2  Hypothesis testing",
    "section": "2.3 Effect size",
    "text": "2.3 Effect size\nIn hypothesis testing, P-values convey only part of the information about the hypothesis and need to be accompanied by an estimation of the effect size, that is, a description of the magnitude of the difference between the study groups. The effect size is a summary statistic that conveys the size of the difference between two groups. For continuous variables, it is usually calculated as the difference between two mean values.\nIf the variable is binary, the effect size can be expressed as the absolute difference between two proportions (attributable risk), or as an odds ratio or relative risk.\nReporting the effect size enables clinicians and other researchers to judge whether a statistically significant result is also a clinically important finding. The size of the difference or the risk statistic provides information to help health professionals decide whether the observed effect is large and important enough to warrant a change in current health care practice, is equivocal and suggests a need for further research, or is small and clinically unimportant."
  },
  {
    "objectID": "04-hypothesis-testing.html#statistical-significance-and-clinical-importance",
    "href": "04-hypothesis-testing.html#statistical-significance-and-clinical-importance",
    "title": "2  Hypothesis testing",
    "section": "2.4 Statistical significance and clinical importance",
    "text": "2.4 Statistical significance and clinical importance\nWhen applying statistical methods in health and medical research, we need to make an informed decision about whether the effect size that led to a statistically significant finding is also clinically important (see Figure 2.1)). The decision about whether a statistically significant result is also clinically important depends on expert knowledge and is best made by practitioners with experience in the field.\n\n\n\nFigure 2.1: Statistical significance vs. clinical importance (Source: Armitage P, Berry G, Matthews JNS. (2001)\n\n\nIt is possible when conducting significance tests, particularly in very large studies, that a small effect is found to be statistically significant. For example, say in a large study of over 1000 patients, a new medication was found to lower blood pressure on average by 1 mmHg more than a currently accepted drug and this was statistically significant (P < 0.05). However, such a small decrease in blood pressure would probably not be considered clinically important. The cost and side effects of prescribing the new medication would need to be weighed against the very small average benefit that would be expected. In this case, although the null hypothesis would be rejected (i.e. the result is statistically significant), the result would not be clinically important. This is the situation described in scenario (c) of Figure Figure 2.1.\nConversely, it is possible to obtain a large, clinically important difference between groups, but a P value that does not demonstrate a statistically significant difference.\nFor example, consider a study to measure the rate of hospital admissions. We may find that 80% of children who present to the Emergency Department are admitted before an intervention is introduced compared to only 65% of children after the intervention. However, the P value may be calculated as 0.11 and is non-significant. This is because only 60 children were surveyed in each period. Here, the reduction in the admission rate by 15% represents a clinically important difference, but not statistically significant. This situation is represented in scenario (d) of Figure 2.1.\nThe important thing to remember is that statistical significance does not always correspond to clinical importance. A statistically significant result may be clinically unimportant, and a statistically non-significant results may be clinically important."
  },
  {
    "objectID": "04-hypothesis-testing.html#errors-in-significance-testing",
    "href": "04-hypothesis-testing.html#errors-in-significance-testing",
    "title": "2  Hypothesis testing",
    "section": "2.5 Errors in significance testing",
    "text": "2.5 Errors in significance testing\nThere are two conclusions we can draw when conducting a hypothesis test: if the P-value is small, there is strong evidence against the null hypothesis and we reject the null hypothesis. If the P-value is not small, there is little evidence against the null hypothesis and we fail to reject the null hypothesis. As discussed above, the “small” cut-point for the P-value is often taken as 0.05. We refer to this value as \\(\\alpha\\) (alpha).\nWe can conduct a thought experiment and compare our hypothesis test conclusion to reality. In reality, either the null hypothesis is true, or it is false. Of course, if we knew what reality was, we would not need to conduct a hypothesis test. But we can compare our possible hypothesis test conclusions to the true (unobserved) reality.\nIf the null hypothesis was true in reality, our hypothesis test can fail to reject the null hypothesis – this would be a correct conclusion. However, the hypothesis test could lead us to rejecting the null hypothesis – this would be an incorrect conclusion. We call this scenario a Type I error, and it has a probability of \\(\\alpha\\).\nThe other situation is where, in reality, the null hypothesis is false. A correct conclusion would be where our hypothesis test rejects the null hypothesis. However, if our hypothesis test fails to reject the null hypothesis, we have made a Type II error. The probability of making a Type II error is denoted \\(\\beta\\) (beta). We will see in Module 10 that \\(\\beta\\) is determined by the size of the study.\nThe error in falsely rejecting the null hypothesis when it is true (type I error), or in falsely accepting the null hypothesis when it is not true (type II error) is summarised in Table 2.2. We will return to these concepts in Module 10, when discussing how to determine the appropriate sample size of a study.\n\n\n\n\nTable 2.2:  Comparison of study result with the truth \n\nStudy resultTruth\n\n EffectNo effect\n\nEvidenceCorrect conclusionɑ\n\nNo evidenceβCorrect conclusion"
  },
  {
    "objectID": "04-hypothesis-testing.html#confidence-intervals-in-hypothesis-testing",
    "href": "04-hypothesis-testing.html#confidence-intervals-in-hypothesis-testing",
    "title": "2  Hypothesis testing",
    "section": "2.6 Confidence intervals in hypothesis testing",
    "text": "2.6 Confidence intervals in hypothesis testing\nIn Module 3, the 95% confidence interval around a mean value was calculated to show the precision of the summary statistic. The 95% confidence intervals around other summary statistics can also be calculated.\nFor example, if we were comparing the means of two groups, we would want to test the null hypothesis that the difference in means is zero, that there is no true difference between the groups.\nFrom the data from the two groups, we could estimate the difference in means, the standard error of the difference in means and the 95% confidence interval around the difference. To estimate the 95% confidence interval, we use the formula given in Module 3, that is:\n\\[ 95\\% \\text{ CI} = \\text{Difference in means} \\pm 1.96 \\times \\text{SE}(\\text{Difference in means)} \\]\nIt is important to remember that the 95% CI is estimated from the standard error, and that the standard error has a direct relationship to the sample size. For small sample sizes, the standard error is large and the 95% CI becomes wider. Conversely, the larger the sample size, the smaller the standard error and the narrower the 95% CI becomes indicating a more precise estimate of the mean difference.\nThe 95% CI tells us the region in which we are 95% confident that the true difference between the groups in the population lies. If this region contains the null value of no difference, we can say that we are 95% confident that there is no true difference between the groups and therefore we would not reject the null hypothesis. This is shown in the top two estimates in Figure 2.2. If the zero value lies outside the 95% confidence interval, we can conclude that there is evidence of a difference between the groups because we are 95% confident that the difference does not encompass a zero value (as shown in the lower two estimates in Figure 2.2.\n\n\n\n\n\nFigure 2.2: Using confidence intervals as informal hypothesis tests\n\n\n\n\nFor relative risk and odds ratio measures, when the 95% CI includes the value of 1 it indicates that we can be 95% confident that the true RR or OR of the association between the study factor and outcome factor includes 1.0 in the source population. This indicates little evidence of an association between the study factor and the outcome factor, e.g. if the results of a study were reported as RR = 1.10 (95% CI 0.95 to 1.25). The P-value can be calculated to assess this (discussed in Module 7).\n\n\n\n\nTable 2.3:  Values indicating no effect \n\nType of outcomeMeasure of effectNull value\n\n(indicating no difference)\n\nContinuousDifference in means0\n\nBinaryDifference in proportions0\n\nRelative risk1\n\nOdds ratio1"
  },
  {
    "objectID": "04-hypothesis-testing.html#one-sample-t-test",
    "href": "04-hypothesis-testing.html#one-sample-t-test",
    "title": "2  Hypothesis testing",
    "section": "2.7 One-sample t-test",
    "text": "2.7 One-sample t-test\nA one-sample t-test tests whether a sample mean is different to a hypothesised value. The t-distribution and its relation to normal distribution has been discussed in detailed in Module 3.\nIn a one-sample t-test, a t-value is computed as the sample mean divided by the standard error of the mean. The significance of the t-value is then computed using software, or can be obtained from a statistical table.\nThe principles of this test can be used for applications such as testing whether the mean of a sample is different from a known population mean, for example testing whether the IQ of a group of children is different from the population mean of 100 IQ points or testing whether the number of average hours worked in an adult sample is different from the population mean of 38 hours.\n\n2.7.1 Worked Example\nThe mean diastolic blood pressure (BP) of the general US population is known to be 71 mm Hg. The diastolic blood pressure of 733 female Pima indigenous Americans was measured and a histogram showed that the data were approximately normally distributed. The mean diastolic blood pressure in the sample was 72.4 mm Hg with a standard deviation of 12.38 mm Hg.\nWe can use Stata or R to conduct a one sample t-test using the data available on Moodle (Example_4.1.csv). The results from this test are summarised below.\n\n\nTable 2.4: Summary of blood pressure from female Pima indigenous Americans\n\n\n\n\n\n\n\n\n\nn\nMean\nStandard deviation\nStandard error\n95% confidence interval of the mean\n\n\n\n\n733\n72.4\n12.38\n0.46\n71.5 to 73.3\n\n\n\n\nThe test statistic for the one-sample t-test is calculated as t732=3.07, with a P-value of 0.002.\nThe mean diastolic blood pressure of females from Pima is estimated as 72.4 mmHg (95% CI: 71.5 to 73.3 mmHg), which is higher than that of the general US population. Note that this interval does not contain the mean of the general US population (71 mm Hg), providing some indication that the mean diastolic blood pressure of female Pima people is higher than that of the general US population.\nThe result from the formal hypothesis test gives strong evidence that the mean diastolic BP of the female Pima people is higher than that of the general US population (t732=3.07, P=0.002)."
  },
  {
    "objectID": "04-hypothesis-testing.html#one-and-two-tailed-tests",
    "href": "04-hypothesis-testing.html#one-and-two-tailed-tests",
    "title": "2  Hypothesis testing",
    "section": "2.8 One and two tailed tests",
    "text": "2.8 One and two tailed tests\nMost statistical tests are two tailed tests, that is, we conduct a test that allows for the summary statistic in the group of interest to be either higher or lower than in the comparison group. For a t-test, this requires that we obtain a two-tailed P value which gives us the probability of the t-value being in either one of the two tails of the t-distribution as shown in Figure 2.3. The shaded regions show the t values that indicate a P value less than 0.05.\n\n\n\n\n\nFigure 2.3: P-value for a 2-tailed test\n\n\n\n\nOccasionally, one tailed tests are conducted in which the summary statistic in the group of interest can only be higher or lower than the comparison group, i.e. a difference is specified to occur in one direction only. This makes it easier to reject the null hypothesis because the consequence is that the P value is essentially halved. The P value for a one tailed test would be 0.025 i.e. the shaded region for a one-tailed test would be doubled on one side of the distribution and eliminated from the other side of the distribution as shown in Figure 2.4.\n\n\n\n\n\nFigure 2.4: P-value for 1-tailed tests\n\n\n\n\nIf a one tailed P value is reported, and is considered to be an invalid decision, it is usually easily converted to a two tailed value by doubling its numeric value. For example, for the same test statistic and sample size:\n\nOne tailed P value = 0.042 i.e. statistically significant\nTwo tailed P value = 0.084 i.e. non-significant\n\nObviously, the choice of whether to use a one or two tailed test is not as important when the P value is highly significant or clearly non-significant but can make a difference to the conclusions when the P value is on the margins of significance.\nIn most health research, the use of a one tailed test is rarely justified because it is unusual to be certain of the direction of effect prior to the research study being undertaken. It has been suggested that if the researchers were sure enough to consider using a one-tailed test, the research study would not be needed.\nIn most studies, two tailed tests of significance are used to allow for the possibility that the effect size could occur in either direction. In clinical trials, this would mean allowing for a result that can indicate a benefit or an adverse effect in response to a new treatment. In epidemiological studies, two tailed tests are used to allow for the fact that exposure to a factor of interest may be adverse or may be beneficial. This conservative approach is usually adopted to prevent missing important effects that occur in the opposite direction to that expected by the researchers."
  },
  {
    "objectID": "04-hypothesis-testing.html#a-note-on-p-values-displayed-by-software",
    "href": "04-hypothesis-testing.html#a-note-on-p-values-displayed-by-software",
    "title": "2  Hypothesis testing",
    "section": "2.9 A note on P-values displayed by software",
    "text": "2.9 A note on P-values displayed by software\nYou will often see P-values generated by statistical software (including Stata) presented as 0.000 or 0.0000. As P-values can never be equal to zero, any P-value displayed in this way should be converted to <0.001 or <0.0001 respectively (i.e. replace the last 0 with a 1, and use the less-than symbol).\nR can display P-values in a very cryptic way: \\(\\text{6.478546e-05}\\) for example. This is translated as:\n\\[\n\\begin{aligned}\n6.478546e-05 &= 6.478546 \\times 10^{-5} \\\\\n  &= 6.478546 \\times 0.00001 \\\\\n  &= 0.00006478546\n\\end{aligned}\n\\]\nAs for the Stata output, such a P-value would be better presented as P<0.0001."
  },
  {
    "objectID": "04-hypothesis-testing.html#decision-tree",
    "href": "04-hypothesis-testing.html#decision-tree",
    "title": "2  Hypothesis testing",
    "section": "2.10 Decision Tree",
    "text": "2.10 Decision Tree\nIn the following modules in this course, several formal statistical tests will be described to analyse different types of data sets that have been collected to test set null hypotheses. It is important that the correct statistical test is selected to generate P-values and estimate effect size. If an incorrect statistical test is used, the assumptions of the test may be violated, the effect size may be biased and the P value generated may be incorrect.\nSelecting the correct test to use in each situation depends on the study design and the nature of the variables collected. Figure 1 in the Appendix shows a decision tree which enables you to decide the type of test to select based on the nature of the data."
  },
  {
    "objectID": "04-hypothesis-testing.html#one-sample-t-test-1",
    "href": "04-hypothesis-testing.html#one-sample-t-test-1",
    "title": "2  Hypothesis testing",
    "section": "2.11 One sample t-test",
    "text": "2.11 One sample t-test\nWe will use data from Example_4.1.csv to demonstrate how a one-sample t-test is conducted in Stata. To perform the test, go to Statistics > Summaries, tables, and tests > Classical tests of hypotheses > t test (mean-comparison test).\nEnsure that the One-sample option is selected, then choose dbp as the Variable name from the drop-down list. Enter the Hypothesised mean value (71 in this example) as shown below.\n\n\n\n\n\nClick OK or Submit to obtain the output below.\n[Command: ttest dbp == 71]\n\n. ttest dbp == 71\n\nOne-sample t test\n------------------------------------------------------------------------------\nVariable |     Obs        Mean    Std. Err.   Std. Dev.   [95% Conf. Interval]\n---------+--------------------------------------------------------------------\n     dbp |     733    72.40518    .4573454    12.38216    71.50732    73.30305\n------------------------------------------------------------------------------\n    mean = mean(dbp)                                              t =   3.0725\nHo: mean = 71                                    degrees of freedom =      732\n\n    Ha: mean < 71               Ha: mean != 71                 Ha: mean > 71\n Pr(T < t) = 0.9989         Pr(|T| > |t|) = 0.0022          Pr(T > t) = 0.0011\n\nThe table gives the sample mean and standard deviation, as well as the standard error and 95% confidence interval of the mean. The test statistics are given under the table: t and the degrees of freedom as well as the P values from two-sided (Ha: mean != 71) and one-sided (Ha: mean <71 and Ha: mean > 71) tests. Refer to the previous sections of this module on the appropriate test to use."
  },
  {
    "objectID": "04-hypothesis-testing.html#one-sample-t-test-2",
    "href": "04-hypothesis-testing.html#one-sample-t-test-2",
    "title": "2  Hypothesis testing",
    "section": "2.12 One sample t-test",
    "text": "2.12 One sample t-test\nWe will use data from Example_4.1.rds to demonstrate how a one-sample t-test is conducted in R.\n\nlibrary(jmv)\n\nbloodpressure <- read.csv(\"data/examples/Example_4.1.csv\")\n\ndescriptives(bloodpressure)\n\n\n DESCRIPTIVES\n\n Descriptives                       \n ────────────────────────────────── \n                         dbp        \n ────────────────────────────────── \n   N                          733   \n   Missing                     35   \n   Mean                  72.40518   \n   Median                      72   \n   Standard deviation    12.38216   \n   Minimum                     24   \n   Maximum                    122   \n ────────────────────────────────── \n\n\nTo test whether the mean diastolic blood pressure of the population from which the sample was drawn is equal to 71, we can use the t.test command:\n\nt.test(bloodpressure$dbp, mu=71)\n\n\n    One Sample t-test\n\ndata:  bloodpressure$dbp\nt = 3.0725, df = 732, p-value = 0.002202\nalternative hypothesis: true mean is not equal to 71\n95 percent confidence interval:\n 71.50732 73.30305\nsample estimates:\nmean of x \n 72.40518 \n\n\nThe output provides:\n\na test statistic (t=3.07);\ndegrees of freedom for the test statistic (df = 732);\na P-value from the two-sided test (P=0.002);\nthe mean of the sample (72.4);\nand the 95% confidence interval of the mean (71.6 to 73.3)."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Acock, Alan C. 2010. A Gentle Introduction to\nStata. 3rd ed. College Station, Tex:\nStata Press.\n\n\nBland, Martin. 2015. An Introduction to Medical\nStatistics. 4th ed. Oxford, New York:\nOxford University Press.\n\n\nKirkwood, Betty, and Jonathan Sterne. 2001. Essentials of\nMedical Statistics. 2nd ed. Malden, Mass:\nWiley-Blackwell."
  }
]