[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PHCM9795: Foundations of Biostatistics",
    "section": "",
    "text": "Course introduction\nWelcome to PHCM9795 Foundations of Biostatistics.\nThis introductory course in biostatistics aims to provide students with core biostatistical skills to analyse and present quantitative data from different study types. These are essential skills required in your degree and throughout your career.\nWe hope you enjoy the course and will value your feedback and comment throughout the course."
  },
  {
    "objectID": "index.html#course-information",
    "href": "index.html#course-information",
    "title": "PHCM9795: Foundations of Biostatistics",
    "section": "Course information",
    "text": "Course information\nBiostatistics is a foundational discipline needed for the analysis and interpretation of quantitative information and its application to population health policy and practice.\nThis course is central to becoming a population health practitioner as the concepts and techniques developed in the course are fundamental to your studies and practice in population health. In this course you will develop an understanding of, and skills in, the core concepts of biostatistics that are necessary for analysis and interpretation of population health data and health literature.\nIn designing this course, we provide a learning sequence that will allow you to obtain the required graduate capabilities identified for your program. This course is taught with an emphasis on formulating a hypothesis and quantifying the evidence in relation to a specific research question. You will have the opportunity to analyse data from different study types commonly seen in population health research.\nThe course will allow those of you who have covered some of this material in your undergraduate and other professional education to consolidate your knowledge and skills. Students exposed to biostatistics for the first time may find the course challenging at times. Based on student feedback, the key to success in this course is to devote time to it every week. We recommend that you spend an average of 10-15 hours per week on the course, including the time spent reading the course notes and readings, listening to lectures, and working through learning activities and completing your assessments. Please use the resources provided to assist you, including online support."
  },
  {
    "objectID": "index.html#units-of-credit",
    "href": "index.html#units-of-credit",
    "title": "PHCM9795: Foundations of Biostatistics",
    "section": "Units of credit",
    "text": "Units of credit\nThis course is a core course of the Master of Public Health, Master of Global Health and Master of Infectious Diseases Intelligence programs and associated dual degrees, comprising 6 units of credit towards the total required for completion of the study program. A value of 6 UOC requires a minimum of 150 hours work for the average student across the term."
  },
  {
    "objectID": "index.html#course-aim",
    "href": "index.html#course-aim",
    "title": "PHCM9795: Foundations of Biostatistics",
    "section": "Course aim",
    "text": "Course aim\nThis course aims to provide students with the core biostatistical skills to apply appropriate statistical techniques to analyse and present population health data."
  },
  {
    "objectID": "index.html#learning-outcomes",
    "href": "index.html#learning-outcomes",
    "title": "PHCM9795: Foundations of Biostatistics",
    "section": "Learning outcomes",
    "text": "Learning outcomes\nOn successful completion of this course, you will be able to:\n\nSummarise and visualise data using statistical software.\nDemonstrate an understanding of statistical inference by interpreting p-values and confidence intervals.\nApply appropriate statistical tests for different types of variables given a research question, and interpret computer output of these tests appropriately.\nDetermine the appropriate sample size when planning a research study.\nPresent and interpret statistical findings appropriate for a population health audience."
  },
  {
    "objectID": "09-non-parametrics.html",
    "href": "09-non-parametrics.html",
    "title": "1  Analysing non-normal data",
    "section": "",
    "text": "Stata notes"
  },
  {
    "objectID": "09-non-parametrics.html#learning-objectives",
    "href": "09-non-parametrics.html#learning-objectives",
    "title": "1  Analysing non-normal data",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of this module you will be able to:\n\nTransform non-normally distributed variables;\nExplain the purpose of non-parametric statistics and key principles for their use;\nCalculate ranks for variables;\nConduct and interpret a non-parametric independent samples significance test;\nConduct and interpret a non-parametric paired samples significance test;\nCalculate and interpret the Spearman rank correlation coefficient."
  },
  {
    "objectID": "09-non-parametrics.html#readings",
    "href": "09-non-parametrics.html#readings",
    "title": "1  Analysing non-normal data",
    "section": "Readings",
    "text": "Readings\nKirkwood and Sterne (2001); Chapter 13. [UNSW Library Link]\nBland (2015); Chapter 12. [UNSW Library Link]\nAcock (2010); Section 7.11."
  },
  {
    "objectID": "09-non-parametrics.html#introduction",
    "href": "09-non-parametrics.html#introduction",
    "title": "1  Analysing non-normal data",
    "section": "1.1 Introduction",
    "text": "1.1 Introduction\nIn general, parametric statistics are preferred for reporting data because the summary statistics (mean, standard deviation, standard error of the mean etc) and the tests used (t-tests, correlation, regression etc) are familiar and the results are easy to communicate. However, non-parametric tests can be used if data are not normally distributed. Non-parametric tests make fewer assumptions about the distribution of the data."
  },
  {
    "objectID": "09-non-parametrics.html#transforming-non-normally-distributed-variables",
    "href": "09-non-parametrics.html#transforming-non-normally-distributed-variables",
    "title": "1  Analysing non-normal data",
    "section": "1.2 Transforming non-normally distributed variables",
    "text": "1.2 Transforming non-normally distributed variables\nWhen a variable has a skewed distribution, one possibility is to transform the data to a new variable to try and obtain a normal or near normal distribution. Methods to transform non-normally distributed data include logarithmic transformation of each data point, or using the square root or the square or the inverse (i.e. 1/x) etc.\n\n1.2.1 Worked Example\nWe have data from 132 patients who had a hospital stay following admission to ICU available on Moodle (Example_9.1.csv). The distribution of the length of stay for these patients is shown in the histogram in Figure 1.1. As is common with variables that record time, the data are skewed with many patients having relatively short stays and a few patients having very long hospital stays. Clearly, it would be inappropriate to use parametric statistical methods for these data.\n\n\n\n\n\nFigure 1.1: Length of hospital stay for 132 patients\n\n\n\n\nWhen data are positively skewed, as shown in Figure 1.1, a logarithmic transformation can often make the data closer to being normally distributed. This is the most common transformation used. You should note, however, that the logarithmic function cannot handle 0 or negative values. One way to deal with zeros in a set of data is to add 1 to each value before taking the logarithm.\nWe would generate a new variable, as shown in the Stata or R notes. As the minimum length of stay in these sample data was 0, we have added 1 to each length of stay before taking the logarithm. The distribution of the logarithm of (length of stay + 1) is shown in Figure 1.2.\n\n\n\n\n\nFigure 1.2: istribution of log transformed (length of stay + 1)\n\n\n\n\nThe distribution now appears much more bell shaped. Table 1.1 shows the descriptive statistics for length of stay before and after logarithmic transformation. Before transformation, the SD is almost as large as the mean value which indicates that the data are skewed and that these statistics are not an accurate description of the centre and spread of the data.\n\n\nTable 1.1: Summary statistics for untransformed and transformed length of stay\n\n\n\n\n\n\n\n\nLength of stay\nlog(Length of stay + 1)\n\n\n\n\nMean (Standard deviation)\n38.1 (35.78)\n3.41 (0.715)\n\n\nMean: 95% confidence interval\n31.9 to 44.2\n3.29 to 3.53\n\n\nMedian [Interquartile range]\n27 [21 to 42]\n3.3 [3.1 to 3.8]\n\n\nRange\n0 to 244\n0 to 5.5\n\n\n\n\nThe mean and standard deviation of the transformed length of stay are in log base e (i.e. ln) units. If we raise the mean of the log of length of stay to the power of \\(e\\), it returns a value of 30.2 days (\\(e^{3.41}=30.2\\)).\nTechnically, this is called the geometric mean of the data, and it has a different interpretation to the usual mean, the arithmetic mean. This is a much better estimate in this case of the “average” length of stay than the mean of 38.1 days (95% CI 31.9, 44.2 days) obtained from the non-transformed positively skewed data. Note that, if you have added 1 to your data to deal with 0 values, the back-transformed estimate is approximately equal to the geometric mean.\nThis set of data also includes a variable summarising whether a patient acquired a nosocomial infection (also known as healthcare-associated infections), which are infections that develop while undergoing medical treatment but were absent at the time of admission.\nIf we were testing the hypothesis that there was a difference in length of stay between groups (status of nosocomial infection), t-tests should not be used with length of stay, but could be used for the log transformed variable, which is approximately normally distributed. The output from the t-test of the log-transformed length of stay is shown in Table 1.2. This is done using the t-test shown in Module 5.\n\n\nTable 1.2: Summary statistics for transformed length of stay\n\n\nNosocomial infection\nn\nMean (SE)\n95% Confidence interval\n\n\n\n\nNo\n106\n3.33 (0.068)\n3.19 to 3.46\n\n\nYes\n26\n3.73 (0.136)\n3.45 to 4.01\n\n\nDifference (Yes - No)\n\n0.39 (0.153)\n0.09 to 0.70\n\n\n\n\nHere, a two-sample t-test gives a test statistic of 2.59 with 130 degrees of freedom, and a P-value of 0.01.\nAs explained above, the estimated statistics would need to be converted back to the units in which the variable was measured. From Output 9.2, we can take the exponential of the corresponding log-transformed values:\n\nthe geometric mean of the infected group is approximately 41.5 days with a 95% confidence interval from 31.4 to 55.0 days.\nthe geometric mean of the uninfected group is approximately 27.9 days with a 95% confidence interval from 24.4 to 31.9 days."
  },
  {
    "objectID": "09-non-parametrics.html#non-parametric-significance-tests",
    "href": "09-non-parametrics.html#non-parametric-significance-tests",
    "title": "1  Analysing non-normal data",
    "section": "1.3 Non-parametric significance tests",
    "text": "1.3 Non-parametric significance tests\nIt is often not possible or sensible to transform a non-normal distribution, for example if there are too many zero values or when we simply want to compare groups using the unit in which the measurement was taken (e.g. length of stay). For this, non-parametric significance tests can be used but the general idea behind these tests is that the data values are replaced by ranks. This also protects against outliers having too much influence.\n\n1.3.1 Ranking variables\nTable 9.1 shows how ranks are calculated for the first 21 patients in the length-of-stay data (Example_9.1.dta). First the data are sorted in order of their magnitude (from the lowest value to the highest) ignoring the group variable. Each data point is then assigned a rank. Data points that are equal are assigned the mean of their ranks. Thus, the two lengths of stay of 11 days share the ranks 4 and 5, and have a mean rank of 4.5. Similarly, there are 5 people with a length of stay of 14 days and these share the ranks 9 to 13, the mean of which is 11. Once ranks are computed they are assigned to each of the two groups and summed within each group.\n\n\n\n\nTransforming data to ranks: first 21 participants\nIDInfectionLength of stayRankInfection=noInfection=Yes\n\n32No011\n\n33No122\n\n12No933\n\n22No114.54.5\n\n16No114.54.5\n\n28Yes1266\n\n27No137.57.5\n\n20No137.57.5\n\n24No141111\n\n11No141111\n\n130No141111\n\n10No141111\n\n25No141111\n\n19No1515.515.5\n\n30No1515.515.5\n\n23No1515.515.5\n\n14No1515.515.5\n\n15No1720.520.5\n\n13No1720.520.5\n\n21Yes1720.520.5\n\n17No1720.520.5\n\n\n\n\nBy assigning ranks to individuals, we lose information about their actual values and this makes it more difficult to detect a difference. However, outliers and extreme values in the data are brought back closer to the data so that they are less influential. For this reason, non-parametric tests have less power than parametric tests and they require much larger differences in the data to show statistical significance between groups."
  },
  {
    "objectID": "09-non-parametrics.html#non-parametric-test-for-two-independent-samples-wilcoxon-ranked-sum-test",
    "href": "09-non-parametrics.html#non-parametric-test-for-two-independent-samples-wilcoxon-ranked-sum-test",
    "title": "1  Analysing non-normal data",
    "section": "1.4 Non-parametric test for two independent samples (Wilcoxon ranked sum test)",
    "text": "1.4 Non-parametric test for two independent samples (Wilcoxon ranked sum test)\nThe non-parametric equivalent to an independent samples t-test (Module 5) is the Wilcoxon ranked sum test, also known as the Mann-Whitney U test. In Stata, this can be obtained using the ranksum command.\nThe assumption for this test is that the distributions of the two populations have the same general shape. If this assumption is met, then this test evaluates the null hypothesis that the medians of the two populations are equal. This test does not assume that the populations are normally distributed, nor that their variances are equal.\nFor the length of stay data in the Worked Example 9.1, we first get a ranks table as shown in Output 9.3. The rank sum table gives us a direction of effect that the ranks are higher than expected in patients who had nosocomial infection. While the positive infection group has a lower sum of ranks because there were fewer people who contracted an infection, it is higher than expected, i.e. they have a longer length of stay compared with the negative infection group. This ranks table does not provide any summary statistics of direction of effect, central tendency or spread that describe the data.\n\nStata Output 9.3: Wilcoxon rank-sum test\n\nTwo-sample Wilcoxon rank-sum (Mann-Whitney) test\n\n      infect |      obs    rank sum    expected\n-------------+---------------------------------\n          No |      106        6620        7049\n         Yes |       26        2158        1729\n-------------+---------------------------------\n    combined |      132        8778        8778\n\nunadjusted variance    30545.67\nadjustment for ties      -53.87\n                     ----------\nadjusted variance      30491.80\n\nHo: los(infect==No) = los(infect==Yes)\n             z =  -2.457\n    Prob > |z| =   0.0140\n    Exact Prob =   0.0135\n\nThe test statistics are shown under the rank sum table in Output 9.3. The variance shown immediately under the table are used to conduct the test, and are not reported on.\nFrom Output 9.3, there are two P-values shown: one assuming normality of the ranks (not the underlying data), and an “Exact” P-value. The exact P-value is calculated when the sample size is not too large (less than 200), and is preferred. The rounded exact P value is 0.014 which indicates that the there is evidence of a difference in length of stay between the groups. This P-value should be provided alongside non-parametric summary statistics such as medians and inter-quartile ranges.\nUsing the summary command with the detail option in Stata and splitting the LOS variable by the Infect variable (as shown in Module 5), we can obtain the median length of stay values of 24 (Interquartile Range: 19 to 40 days) in the group with no infection and 37 (Interquartile Range: 24 to 50 days) in the group with infection."
  },
  {
    "objectID": "09-non-parametrics.html#non-parametric-test-for-paired-data-wilcoxon-signed-rank-test",
    "href": "09-non-parametrics.html#non-parametric-test-for-paired-data-wilcoxon-signed-rank-test",
    "title": "1  Analysing non-normal data",
    "section": "1.5 Non-parametric test for paired data (Wilcoxon signed-rank test)",
    "text": "1.5 Non-parametric test for paired data (Wilcoxon signed-rank test)\nThere are two types of non-parametric tests for paired data, called the Sign test and the Wilcoxon signed rank test. In practice, the Sign test is rarely used and will not be discussed in this course.\nIf the differences between two paired measurements are not normally distributed, a non-parametric equivalent of a paired t-test (Module 5) should be used. The equivalent test is the Wilcoxon matched-pairs signed rank test, also simply called the Wilcoxon matched-pairs test. This test is resistant to outliers in the data, however the proportion of outliers in the sample should be small. This test evaluates the null hypothesis that the median of the paired differences is equal to zero.\nIn this test, the absolute differences between the paired scores are ranked and the difference scores that are equal to zero (i.e. scores where there is no difference between the pairs) are excluded. Thus, the test is not suitable when a large proportion of the differences are zero because the effective sample size is reduced considerably.\n\n1.5.1 Worked Example\nA crossover trial is done to compare symptom scores for two drugs in 11 people with arthritis (higher scores indicate more severe symptoms). The data are contained in Stata datafile file Example_9.2.dta. The data are shown in Table 9.2. The descriptive statistics indicate that the differences are not normally distributed. You can use the Explore function in Stata to determine this.\n\n\n\n\nArthritis symptom scores for 11 patients after administering two drugs\nPatient IDScore: Drug 1Score: Drug 2Difference (Drug 2 – Drug 1)\n\n1341\n\n2275\n\n3341\n\n48102\n\n5682\n\n661-5\n\n7264\n\n8374\n\n9583\n\n109101\n\n11781\n\n\n\n\nBefore doing the analysis let us examine the distribution of the difference of symptom scores between the two drugs. As in Module 5, we first need to compute the difference between the symptom scores. To examine the distribution, we plot a histogram as shown in Figure @ref(fig:mod09-diff-hist).\n\n\n\n\n\nDistribution of difference in symptom scores between Drug 1 and Drug 2\n\n\n\n\nThe histogram shows that the differences are not normally distributed. The data looks negatively skewed with a gap in the histogram between the values of -5 and 0. Therefore, it would not be appropriate to conduct a paired t-test. Hence, we conduct a non-parametric paired test (Wilcoxon matched-pairs signed-rank test).\nA non-parametric paired test can be obtained in Stata using the signrank command and the results of the test are shown in Output 9.4.\n\nStata Output 9.4: Wilcoxon matched-pairs signed-rank test\n\nWilcoxon signed-rank test\n\n        sign |      obs   sum ranks    expected\n-------------+---------------------------------\n    positive |        1        10.5          33\n    negative |       10        55.5          33\n        zero |        0           0           0\n-------------+---------------------------------\n         all |       11          66          66\n\nunadjusted variance      126.50\nadjustment for ties       -1.63\nadjustment for zeros       0.00\n                     ----------\nadjusted variance        124.88\n\nHo: drug_1 = drug_2\n             z =  -2.013\n    Prob > |z| =   0.0441\n    Exact Prob =   0.0459\n\nThe table in Output 9.4 shows that there is 1 person who has a positive difference, where the symptom score on drug 2 that is smaller than that for drug 1 (i.e., drug 2 is better than drug 1); and 10 people who have a negative difference. No one has the same score for both drugs. The difference scores are ranked and the observed and expected sum of the ranks are shown in the output. This provides no intuitive summary statistics except to indicate which drug has higher ranks.\nThe test statistics are also shown under the table in Output 9.4. From the output, the exact P value of 0.046 indicates that there is evidence of a difference in symptom score between the two drugs."
  },
  {
    "objectID": "09-non-parametrics.html#non-parametric-estimates-of-correlation",
    "href": "09-non-parametrics.html#non-parametric-estimates-of-correlation",
    "title": "1  Analysing non-normal data",
    "section": "1.6 Non-parametric estimates of correlation",
    "text": "1.6 Non-parametric estimates of correlation\nEstimating correlation using Pearson’s correlation coefficient can be problematic when bivariate Normality cannot be assumed, or in the presence of outliers or skewness. There are two commonly used non-parametric alternatives to Pearson’s correlation coefficient: Spearman’s rank correlation (\\(\\rho\\) or rho), and Kendall’s rank correlation (\\(\\tau\\) or tau).\nWhen estimating the correlation between x and y, Spearman’s rank correlation essentially replaces the observations x and y by their ranks, and calculates the correlation between the ranks. Kendall’s rank correlation compares the ranks between every possible combination of pairs of data to measure concordance: whether high values for x tend to be associated with high values for y (positively correlated) or low values of y (negatively correlated).\nIn terms of which is the more appropriate measure to use, the following passage from An Introduction to Medical Statistics (Bland (2015)) provides some guidance:\n\n“Why have two different rank correlation coefficients? Spearman’s \\(\\rho\\) is older than Kendall’s \\(\\tau\\), and can be thought of as a simple analogue of the product moment correlation coefficient, Pearson’s r. Kendall’s \\(\\tau\\) is a part of a more general and consistent system of ranking methods, and has a direct interpretation, as the difference between the proportions of concordant and discordant pairs. In general, the numerical value of \\(\\rho\\) is greater than that of \\(\\tau\\). It is not possible to calculate \\(\\tau\\) from \\(\\rho\\) or \\(\\rho\\) from \\(\\tau\\), they measure different sorts of correlation. \\(\\rho\\) gives more weight to reversals of order when data are far apart in rank than when there is a reversal close together in rank, \\(\\tau\\) does not. However, in terms of tests of significance, both have the same power to reject a false null hypothesis, so for this purpose it does not matter which is used.”\n\nWe will illustrate estimating rank correlation using the Stata file Example_8.1.dta, which has information about height and lung function collected from a sample of 120 adults.\nThe Spearman rank correlation coefficient is estimated as 0.75, demonstrating a positive association between height and FVC. The Kendall rank correlation coefficient is estimated as 0.56, again demonstrating a positive association between height and FVC."
  },
  {
    "objectID": "09-non-parametrics.html#summary",
    "href": "09-non-parametrics.html#summary",
    "title": "1  Analysing non-normal data",
    "section": "1.7 Summary",
    "text": "1.7 Summary\nIn this module, we have presented methods to conduct a hypothesis test with data that are not normally distributed. Non-parametric methods do not assume any distribution for the data and use significance tests based on ranks or sign (or both). A non-parametric test is always less powerful than its equivalent parametric test if the data are normally distributed and so whenever possible parametric significance tests should be used. In some cases when data are not normally distributed with a reasonably large sample size, the data can be transformed (most commonly by log transformation) to make the distribution normal. A parametric significance test should then be used with the transformed data to test the hypothesis."
  },
  {
    "objectID": "09-non-parametrics.html#transforming-non-normally-distributed-variables-1",
    "href": "09-non-parametrics.html#transforming-non-normally-distributed-variables-1",
    "title": "1  Analysing non-normal data",
    "section": "1.8 Transforming non-normally distributed variables",
    "text": "1.8 Transforming non-normally distributed variables\nOne option for dealing with a non-normally distributed varaible is to transform it into its square, square root or logarithmic value. The new transformed variable may be normally distributed and therefore a parametric test can be used. First we check the distribution of the variable for normality, e.g. by plotting a histogram (for example, Figure 9.1).\nYou can calculate a new, transformed, variable using the generate command in Stata from the menu Data > Create or change data > Create new variable. Below are the instructions for creating a log to the base e, referred to as “ln” of the length of stay data for Example_9.1.dta.\nGo to Data > Create or change data > Create new variable. In the generate dialog box, type a name for your new variable into the Variable name: box: for example, ln_los. To include the ln function, you can either:\n\nsimply type ln(los + 1) directly into the Specify a value or an expression text box, or;\nclick the Create button to bring up the Expression Builder dialog box. Double click on Functions to expand the list in the Categories box, then click on Mathematical to display the list of mathematical functions in the box on the right. Scroll down to the ln() function and double click on it to bring it to the main text box. Next scroll down the Categories box to Variables and click on it to check the variables you have in the dataset. In the text box, replace x with los + 1 as shown below.\n\n\n\n\n\n\nClick the OK button when you are done to transfer the expression to the Specify a value or an expression box in the generate dialog box as shown below.\n\n\n\n\n\nClick OK and the new variable will appear in your dataset. You can check in your Variables window or your Data Editor window.\n[Command: gen ln_los=ln(los + 1)]\nYou can now check whether this variable is normally distributed as described in Module 2, for example with the histogram command as shown in Figure 9.2.\nTo obtain the back-transformed mean shown in Output 9.1, go to Data > Other Utilities > Hand calculator. In the display dialog box, expand the Functions list in the Categories box and select Mathematical. On the right-hand-side box, double-click on exp(). Replace x with the mean, 3.407232 as shown below.\nClick OK when you are done, then OK or Submit in the display dialog box.\n\n\n\n\n\n[Command: di exp(3.407232)]\nIf your transformed variable is approximately normally distributed, you can apply parametric tests such as the t-test. In the Worked Example 9.1 dataset, the variable infect (presence of nosocomial infection) is a binary categorical variable. To test the hypothesis that patients with nosocomial infection have a different length of stay to patients without infection, you can conduct a t-test on the ln_los variable. You will need to back transform your mean values, as shown in Worked Example 9.1 in the course notes when reporting your results."
  },
  {
    "objectID": "09-non-parametrics.html#wilcoxon-ranked-sum-test",
    "href": "09-non-parametrics.html#wilcoxon-ranked-sum-test",
    "title": "1  Analysing non-normal data",
    "section": "1.9 Wilcoxon ranked-sum test",
    "text": "1.9 Wilcoxon ranked-sum test\nThe Wilcoxon ranked-sum test will be demonstrated using the length of stay data in Example_9.1.dta. To perform the Wilcoxon ranked-sum test go to: Statistics > Summaries, tables, and tests > Nonparametric tests of hypotheses > Wilcoxon ranked-sum test.\nIn the ranksum dialog box, select los as the Variable and select infect as the Grouping variable as shown below.\n\n\n\n\n\nClick OK or Submit to obtain Output 9.3.\n[Command: ranksum los, by(infect)]"
  },
  {
    "objectID": "09-non-parametrics.html#wilcoxon-matched-pairs-signed-rank-test",
    "href": "09-non-parametrics.html#wilcoxon-matched-pairs-signed-rank-test",
    "title": "1  Analysing non-normal data",
    "section": "1.10 Wilcoxon matched-pairs signed-rank test",
    "text": "1.10 Wilcoxon matched-pairs signed-rank test\nThe Wilcoxon matched-pairs signed-rank test in Stata will be demonstrated using the dataset on the arthritis drug cross-over trial (Example_9.2.dta). Like the paired t-test the paired data need to be in separate columns.\nTo do the analysis, go to: Statistics > Summaries, tables, and tests > Nonparametric tests of hypotheses > Wilcoxon matched-pairs sign-rank test. In the signrank dialog box, select drug_1 in the Variable box and type drug_2 in the Expression box. The dialog box will look like:\n\n\n\n\n\nClick OK or Submit to obtain Output 9.4. [Command: signrank drug_1 = drug_2]"
  },
  {
    "objectID": "09-non-parametrics.html#estimating-rank-correlation-coefficients",
    "href": "09-non-parametrics.html#estimating-rank-correlation-coefficients",
    "title": "1  Analysing non-normal data",
    "section": "1.11 Estimating rank correlation coefficients",
    "text": "1.11 Estimating rank correlation coefficients\nThe analyses for Spearman’s and Kendall’s rank correlation are conducted in similar ways.\nStatistics > Nonparametric analysis > Tests of hypotheses > Spearman’s rank correlation\n\n\n\n\n\nGiving the following output:\n\n. spearman Height FVC\n\n Number of obs =     120\nSpearman's rho =       0.7476\n\nTest of Ho: Height and FVC are independent\n    Prob > |t| =       0.0000\n\nStatistics > Nonparametric analysis > Tests of hypotheses > Kendall’s rank correlation\n\n\n\n\n\n\n. ktau Height FVC\n\n  Number of obs =     120\nKendall's tau-a =       0.5431\nKendall's tau-b =       0.5609\nKendall's score =    3878\n    SE of score =     439.463   (corrected for ties)\n\nTest of Ho: Height and FVC are independent\n     Prob > |z| =       0.0000  (continuity corrected)\n\nStata provides two versions of the Kendall rank correlation coefficient: we would use tau-b (\\(\\tau_b\\)) as it allows for tied observations."
  },
  {
    "objectID": "09-non-parametrics.html#transforming-non-normally-distributed-variables-2",
    "href": "09-non-parametrics.html#transforming-non-normally-distributed-variables-2",
    "title": "1  Analysing non-normal data",
    "section": "1.12 Transforming non-normally distributed variables",
    "text": "1.12 Transforming non-normally distributed variables\nOne option for dealing with a non-normally distributed varaible is to transform it into its square, square root or logarithmic value. The new transformed variable may be normally distributed and therefore a parametric test can be used. First we check the distribution of the variable for normality, e.g. by plotting a histogram.\nYou can calculate a new, transformed, variable using standard commands. For example, to create a new column of data based on the log of length of stay:\n\nlibrary(jmv)\n\nhospital <- readRDS(\"data/examples/Example_9.1.rds\")\n\nhospital$ln_los <- log(hospital$los+1)\ndescriptives(data=hospital, vars=c(los, ln_los))\n\n\n DESCRIPTIVES\n\n Descriptives                                    \n ─────────────────────────────────────────────── \n                         los         ln_los      \n ─────────────────────────────────────────────── \n   N                          132          132   \n   Missing                      0            0   \n   Mean                  38.05303     3.407232   \n   Median                27.00000     3.332205   \n   Standard deviation    35.78057    0.7149892   \n   Minimum               0.000000     0.000000   \n   Maximum               244.0000     5.501258   \n ─────────────────────────────────────────────── \n\n\nYou can now check whether this logged variable is normally distributed as described in Module 2, for example by plotting a histogram as shown in Figure 9.2.\nTo obtain the back-transformed mean, we can use the exp command to anti-log the mean:\n\nexp(3.407232)\n\n[1] 30.18159\n\n\nIf your transformed variable is approximately normally distributed, you can apply parametric tests such as the t-test. In the Worked Example 9.1 dataset, the variable infect (presence of nosocomial infection) is a binary categorical variable. To test the hypothesis that patients with nosocomial infection have a different length of stay to patients without infection, you can conduct a t-test on the ln_los variable. You will need to back transform your mean values, as shown in Worked Example 9.1 in the course notes when reporting your results."
  },
  {
    "objectID": "09-non-parametrics.html#wilcoxon-ranked-sum-test-1",
    "href": "09-non-parametrics.html#wilcoxon-ranked-sum-test-1",
    "title": "1  Analysing non-normal data",
    "section": "1.13 Wilcoxon ranked-sum test",
    "text": "1.13 Wilcoxon ranked-sum test\nWe use the wilcox.test function to perform the Wilcoxon ranked-sum test:\nwilcox.test(continuous_variable ~ group_variable, data=df)\nNote that the implementation of R’s Wilcoxon rank-sum test uses a “continuity correction” for calculating the P-value from the ranks. This differs from Stata which does not use the continuity correction. While the use of the continuity correction is preferable, in most cases the difference in P-values between the methods will be minimal.\nTo obtain results that are consistent with Stata, the correct=FALSE option can be used:\nwilcox.test(continuous_variable ~ group_variable, data=df, correct=FALSE)\nThe Wilcoxon ranked-sum test will be demonstrated using the length of stay data in Example_9.1.rds. Here, out continuous variable is los and the grouping variable is infect.\n\nwilcox.test(los ~ infect, data=hospital)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  los by infect\nW = 949, p-value = 0.01413\nalternative hypothesis: true location shift is not equal to 0"
  },
  {
    "objectID": "09-non-parametrics.html#wilcoxon-matched-pairs-signed-rank-test-1",
    "href": "09-non-parametrics.html#wilcoxon-matched-pairs-signed-rank-test-1",
    "title": "1  Analysing non-normal data",
    "section": "1.14 Wilcoxon matched-pairs signed-rank test",
    "text": "1.14 Wilcoxon matched-pairs signed-rank test\nThe wilcox.test function can also be used to conduct the Wilcoxon matched-pairs signed-rank test. The specification of the variables is a little different, in that each variable is specified as dataframe$variable:\nwilcox.test(df$continuous_variable_1, df$continuous_variable_1, paired=TRUE)\nWe will demonstrate using the dataset on the arthritis drug cross-over trial (Example_9.2.rds). Like the paired t-test the paired data need to be in separate columns.\n\narthritis <- readRDS(\"data/examples/Example_9.2.rds\")\n\narthritis$difference = arthritis$drug_1 - arthritis$drug_2\n\nhist(arthritis$difference, xlab=\"Difference\", main=\"Histogram of differences in pain scores\")\n\n\n\nwilcox.test(arthritis$drug_1, arthritis$drug_2, \n            paired=TRUE)\n\nWarning in wilcox.test.default(arthritis$drug_1, arthritis$drug_2, paired =\nTRUE): cannot compute exact p-value with ties\n\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  arthritis$drug_1 and arthritis$drug_2\nV = 10.5, p-value = 0.04898\nalternative hypothesis: true location shift is not equal to 0"
  },
  {
    "objectID": "09-non-parametrics.html#estimating-rank-correlation-coefficients-1",
    "href": "09-non-parametrics.html#estimating-rank-correlation-coefficients-1",
    "title": "1  Analysing non-normal data",
    "section": "1.15 Estimating rank correlation coefficients",
    "text": "1.15 Estimating rank correlation coefficients\nThe analyses for Spearman’s and Kendall’s rank correlation are conducted in similar ways:\n\nlung <- readRDS(\"data/examples/Example_8.1.rds\")\n\ncor.test(lung$Height, lung$FVC, method=\"spearman\")\n\nWarning in cor.test.default(lung$Height, lung$FVC, method = \"spearman\"): Cannot\ncompute exact p-value with ties\n\n\n\n    Spearman's rank correlation rho\n\ndata:  lung$Height and lung$FVC\nS = 72699, p-value < 2.2e-16\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.7475566 \n\ncor.test(lung$Height, lung$FVC, method=\"kendall\")\n\n\n    Kendall's rank correlation tau\n\ndata:  lung$Height and lung$FVC\nz = 8.8244, p-value < 2.2e-16\nalternative hypothesis: true tau is not equal to 0\nsample estimates:\n      tau \n0.5609431"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Acock, Alan C. 2010. A Gentle Introduction to\nStata. 3rd ed. College Station, Tex:\nStata Press.\n\n\nBland, Martin. 2015. An Introduction to Medical\nStatistics. 4th ed. Oxford, New York:\nOxford University Press.\n\n\nKirkwood, Betty, and Jonathan Sterne. 2001. Essentials of\nMedical Statistics. 2nd ed. Malden, Mass:\nWiley-Blackwell."
  }
]